{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.experimental import optimizers\n",
    "import numpy as onp\n",
    "from jax import random\n",
    "from jax import jit\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import time\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "batch_size = 100\n",
    "\n",
    "mnist_data, info = tfds.load(name=\"mnist\", batch_size=-1, with_info=True)\n",
    "mnist_data = tfds.as_numpy(mnist_data)\n",
    "train_data, test_data = mnist_data['train'], mnist_data['test']\n",
    "num_labels = info.features['label'].num_classes\n",
    "h, w, c = info.features['image'].shape\n",
    "num_pixels = h * w * c\n",
    "\n",
    "# Full train set\n",
    "train_images, train_labels = train_data['image'], train_data['label']\n",
    "train_images = np.reshape(train_images, (len(train_images), num_pixels))\n",
    "train_labels = np.reshape(train_labels, (len(train_labels), ))\n",
    "#reshape each section, then merge the tensors into a dataset\n",
    "train_data = TensorDataset(torch.Tensor(train_images), torch.Tensor(train_labels))\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Full test set\n",
    "test_images, test_labels = test_data['image'], test_data['label']\n",
    "test_images = np.reshape(test_images, (len(test_images), num_pixels))\n",
    "test_labels = np.reshape(test_labels, (len(test_labels), ))\n",
    "test_data = TensorDataset(torch.Tensor(test_images), torch.Tensor(test_labels))\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_mlp(sizes, key):\n",
    "    \"\"\" Initialize the weights of all layers of a linear layer network \"\"\"\n",
    "    keys = random.split(key, len(sizes))\n",
    "    # Initialize a single layer with Gaussian weights -  helper function\n",
    "    def initialize_layer(m, n, key, scale=1e-2):\n",
    "        w_key, b_key = random.split(key)\n",
    "        return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
    "    return [initialize_layer(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
    "\n",
    "layer_sizes = [784, 512, 512, 10]\n",
    "# Return a list of tuples of layer weights (weight,bias)\n",
    "params = initialize_mlp(layer_sizes, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "from jax import jit, grad, random\n",
    "from jax.experimental import optimizers\n",
    "from jax.experimental import stax\n",
    "from jax.experimental.stax import Dense, Relu, LogSoftmax\n",
    "\n",
    "init_random_params, predict = stax.serial(\n",
    "    Dense(512), Relu,\n",
    "    Dense(10), LogSoftmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-class cross-entropy loss between one-hot encoded class labels and softmax output\n",
    "def one_hot(x, k, dtype=np.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k \"\"\"\n",
    "    return np.array(x[:, None] == np.arange(k), dtype)\n",
    "\n",
    "def loss(params, images, targets):\n",
    "    \"\"\" Compute the multi-class cross-entropy loss \"\"\"\n",
    "    preds = predict(params, images)\n",
    "    return -np.sum(preds * targets)\n",
    "\n",
    "def accuracy(params, data_loader):\n",
    "    \"\"\" Compute the accuracy for a provided dataloader \"\"\"\n",
    "    acc_total = 0\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        images = np.array(data).reshape(data.size(0), 28*28)\n",
    "        targets = one_hot(np.array(target), num_classes)\n",
    "        target_class = np.argmax(targets, axis=1)\n",
    "        predicted_class = np.argmax(predict(params, images), axis=1)\n",
    "        acc_total += np.sum(predicted_class == target_class)\n",
    "    return acc_total/len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(params, x, y, opt_state):\n",
    "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
    "    value, grads = value_and_grad(loss)(params, x, y)\n",
    "    opt_state = opt_update(0, grads, opt_state)\n",
    "    return get_params(opt_state), opt_state, value\n",
    "\n",
    "# Defining an optimizer in Jax\n",
    "step_size = 1e-3\n",
    "opt_init, opt_update, get_params = optimizers.adam(step_size)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "num_epochs = 10\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Incompatible shapes for dot: got (100, 784) and (512, 784).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-cfb690aee541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m train_loss, train_log, test_log = run_mnist_training_loop(num_epochs,\n\u001b[0m\u001b[1;32m     37\u001b[0m                                                           opt_state)\n",
      "\u001b[0;32m<ipython-input-43-cfb690aee541>\u001b[0m in \u001b[0;36mrun_mnist_training_loop\u001b[0;34m(num_epochs, opt_state)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Get initial accuracy after random init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlog_acc_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-93d93ddc09f0>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(params, data_loader)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtarget_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0macc_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0macc_total\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jax/jax/experimental/stax.py\u001b[0m in \u001b[0;36mapply_fun\u001b[0;34m(params, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mrngs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrng\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_funs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrngs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0minit_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jax/jax/experimental/stax.py\u001b[0m in \u001b[0;36mapply_fun\u001b[0;34m(params, inputs, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mapply_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0minit_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jax/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(a, b, precision)\u001b[0m\n\u001b[1;32m   3620\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3621\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3622\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3624\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mb_ndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jax/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(lhs, rhs, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m    635\u001b[0m                        precision=precision, preferred_element_type=preferred_element_type)\n\u001b[1;32m    636\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m     raise TypeError(\"Incompatible shapes for dot: got {} and {}.\".format(\n\u001b[0m\u001b[1;32m    638\u001b[0m         lhs.shape, rhs.shape))\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Incompatible shapes for dot: got (100, 784) and (512, 784)."
     ]
    }
   ],
   "source": [
    "def run_mnist_training_loop(num_epochs, opt_state):\n",
    "    \"\"\" Implements a learning loop over epochs. \"\"\"\n",
    "    # Initialize placeholder for loggin\n",
    "    log_acc_train, log_acc_test, train_loss = [], [], []\n",
    "\n",
    "    # Get the initial set of parameters\n",
    "    params = get_params(opt_state)\n",
    "\n",
    "    # Get initial accuracy after random init\n",
    "    train_acc = accuracy(params, train_loader)\n",
    "    test_acc = accuracy(params, test_loader)\n",
    "    log_acc_train.append(train_acc)\n",
    "    log_acc_test.append(test_acc)\n",
    "\n",
    "    # Loop over the training epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Flatten the image into 784 vectors for the MLP\n",
    "            x = np.array(data).reshape(data.size(0), 28*28)\n",
    "            y = one_hot(np.array(target), num_classes)\n",
    "            params, opt_state, loss = update(params, x, y, opt_state)\n",
    "            train_loss.append(loss)\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        train_acc = accuracy(params, train_loader)\n",
    "        test_acc = accuracy(params, test_loader)\n",
    "        log_acc_train.append(train_acc)\n",
    "        log_acc_test.append(test_acc)\n",
    "        print(\"Epoch {} | T: {:0.2f} | Train A: {:0.3f} | Test A: {:0.3f}\".format(epoch+1, epoch_time,\n",
    "                                                                    train_acc, test_acc))\n",
    "\n",
    "    return train_loss, log_acc_train, log_acc_test\n",
    "\n",
    "\n",
    "train_loss, train_log, test_log = run_mnist_training_loop(num_epochs,\n",
    "                                                          opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

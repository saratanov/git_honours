{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [14:47:38] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "/Users/u6676643/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#delfos copy for pka prediction\n",
    "import torch\n",
    "from torch import nn\n",
    "from mol2vec.features import mol2alt_sentence, mol2sentence, MolSentence, DfVec, sentences2vec\n",
    "from gensim.models import word2vec\n",
    "import pandas as pd\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import Chem\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: define solvent X and solute Y using mol2vec but don't add the substructures!!\n",
    "#step 2: run RNN in both directions on each molecule, then concatenate forward;reverse to get H and G\n",
    "#step 3: feed H and G into attention layer, generate attention alignment matrix, create contexts P and Q\n",
    "#step 4: maxpool H;P and G;Q into 2D feature vectors\n",
    "#step 5: create flattened input u;v and feed into linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified sentence2vec function to return lists of word vectors\n",
    "def sentences2vecs(sentences, model, unseen=None):\n",
    "    \"\"\"Generate vectors for each word in a sentence sentence (list) in a list of sentences.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sentences : list, array\n",
    "        List with sentences\n",
    "    model : word2vec.Word2Vec\n",
    "        Gensim word2vec model\n",
    "    unseen : None, str\n",
    "        Keyword for unseen words. If None, those words are skipped.\n",
    "        https://stats.stackexchange.com/questions/163005/how-to-set-the-dictionary-for-text-analysis-using-neural-networks/163032#163032\n",
    "    Returns\n",
    "    -------\n",
    "    list of arrays, each sentence -> array of word vectors\n",
    "    \"\"\"\n",
    "    keys = set(model.wv.key_to_index)\n",
    "    bigveclist = []\n",
    "    if unseen:\n",
    "        unseen_vec = model.wv.get_vector(unseen)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        veclist = []\n",
    "        if unseen:\n",
    "            veclist.append([model.wv.get_vector(y) if y in set(sentence) & keys\n",
    "                       else unseen_vec for y in sentence])\n",
    "        else:\n",
    "            veclist.append([model.wv.get_vector(y) for y in sentence \n",
    "                            if y in set(sentence) & keys])\n",
    "        vecarray = np.concatenate(veclist, axis=1)\n",
    "        vectensor = torch.Tensor(vecarray)\n",
    "        bigveclist.append(vectensor)\n",
    "    return bigveclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: mol2vec embedding\n",
    "\n",
    "data = pd.read_csv('data/ETMdata.csv')\n",
    "\n",
    "#mol2vec model\n",
    "mol2vec_model = word2vec.Word2Vec.load('models/model_300dim.pkl')\n",
    "\n",
    "#create mol type\n",
    "data['sol_mol'] = data.apply(lambda x: Chem.MolFromSmiles(x['solute']), axis=1)\n",
    "data['solv_mol'] = data.apply(lambda x: Chem.MolFromSmiles(x['solvent']), axis=1)\n",
    "\n",
    "#remove invalid smiles\n",
    "#data.replace(\"\", float(\"NaN\"), inplace=True)\n",
    "#data.dropna(subset = ['mol'], inplace=True)\n",
    "#print(data)\n",
    "\n",
    "#create sentences\n",
    "data['sol_sentence'] = data.apply(lambda x: mol2alt_sentence(x['sol_mol'],1), axis=1)\n",
    "data['solv_sentence'] = data.apply(lambda x: mol2alt_sentence(x['solv_mol'],1), axis=1)\n",
    "\n",
    "targets = torch.Tensor(data['pka'])\n",
    "sol_data = sentences2vecs(data['sol_sentence'], mol2vec_model, unseen='UNK')\n",
    "solv_data = sentences2vecs(data['solv_sentence'], mol2vec_model, unseen='UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.nn.utils.rnn import pack_sequence\n",
    "#X = pack_sequence(X,enforce_sorted = False)\n",
    "##TODO BATCHING VARIABLE SEQUENCE LENGTHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(G,H):\n",
    "    alpha = torch.exp(H@torch.t(G))\n",
    "    norm = torch.sum(alpha, dim=1)\n",
    "    norm = torch.pow(norm, -1)\n",
    "    alpha = alpha * norm[:, None]\n",
    "    return alpha\n",
    "\n",
    "def att(G,H):\n",
    "    Q = alpha(G,H)@G\n",
    "    inH = torch.cat((H,Q),1)\n",
    "    return inH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "epochs = 10\n",
    "n_features = 300\n",
    "n_hidden = 100\n",
    "\n",
    "class maxpool(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(maxpool, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d((L,2), stride=2)\n",
    "    def forward(self, X):\n",
    "        return self.maxpool(X)\n",
    "\n",
    "class dnet(nn.Module):\n",
    "    def __init__(self, n_features, D, FF):\n",
    "        super(dnet, self).__init__()\n",
    "    \n",
    "        self.biLSTM_X = nn.LSTM(n_features, D, bidirectional=True)\n",
    "        self.biLSTM_Y = nn.LSTM(n_features, D, bidirectional=True)\n",
    "        \n",
    "        self.FF = nn.Linear(4*D, FF)\n",
    "        self.out = nn.Linear(FF, 1)\n",
    "    \n",
    "    def forward(self,X,Y):\n",
    "        N = X.data.shape[0]\n",
    "        M = Y.data.shape[0]\n",
    "        \n",
    "        #turn input list of vec into correct shape\n",
    "        X = X.view(X.data.shape[0],1,X.data.shape[1]) #N rows\n",
    "        Y = Y.view(Y.data.shape[0],1,Y.data.shape[1]) #M rows\n",
    "        \n",
    "        #biLSTM to get hidden states\n",
    "        H, hcX = self.biLSTM_X(X, None) #Nx1x2D matrix\n",
    "        G, hcY = self.biLSTM_Y(Y, None) #Mx1x2D matrix\n",
    "        \n",
    "        #contexts\n",
    "        inG = att(H[:,0,:],G[:,0,:]) #Nx4D\n",
    "        inH = att(G[:,0,:],H[:,0,:]) #Mx4D\n",
    "        \n",
    "        #maxpool concatenated tensors\n",
    "        maxpool_X = maxpool(N)\n",
    "        maxpool_Y = maxpool(M)\n",
    "        u = maxpool_X(inH.view(1,inH.data.shape[0],inH.data.shape[1]))  #1x1x2D\n",
    "        v = maxpool_Y(inG.view(1,inG.data.shape[0],inG.data.shape[1]))  #1x1x2D\n",
    "        \n",
    "        #feed forward neural network\n",
    "        NN = torch.cat((u,v),2)\n",
    "        NN = self.FF(NN)\n",
    "        NN = nn.functional.relu(NN)\n",
    "        output = self.out(NN)\n",
    "        return output\n",
    "\n",
    "dmodel = dnet(300,150,2000)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(dmodel.parameters(), lr=0.0002, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition, 3D maxpool\n",
    "epochs = 10\n",
    "n_features = 300\n",
    "n_hidden = 100\n",
    "\n",
    "class maxpool(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(maxpool, self).__init__()\n",
    "        self.maxpool = nn.MaxPool3d((L,1,2), stride=1)\n",
    "    def forward(self, X):\n",
    "        return self.maxpool(X)\n",
    "    \n",
    "def att(G,H):\n",
    "    Q = alpha(G,H)@G\n",
    "    inH = torch.stack([H,Q],2)\n",
    "    return inH\n",
    "\n",
    "class dnet(nn.Module):\n",
    "    def __init__(self, n_features, D, FF):\n",
    "        super(dnet, self).__init__()\n",
    "    \n",
    "        self.biLSTM_X = nn.LSTM(n_features, D, bidirectional=True)\n",
    "        self.biLSTM_Y = nn.LSTM(n_features, D, bidirectional=True)\n",
    "        \n",
    "        self.FF = nn.Linear(4*D, FF)\n",
    "        self.out = nn.Linear(FF, 1)\n",
    "    \n",
    "    def forward(self,X,Y):\n",
    "        N = X.data.shape[0]\n",
    "        M = Y.data.shape[0]\n",
    "        \n",
    "        #turn input list of vec into correct shape\n",
    "        X = X.view(X.data.shape[0],1,X.data.shape[1]) #N rows\n",
    "        Y = Y.view(Y.data.shape[0],1,Y.data.shape[1]) #M rows\n",
    "        \n",
    "        #biLSTM to get hidden states\n",
    "        H, hcX = self.biLSTM_X(X, None) #Nx1x2D matrix\n",
    "        G, hcY = self.biLSTM_Y(Y, None) #Mx1x2D matrix\n",
    "        \n",
    "        #contexts\n",
    "        inG = att(H[:,0,:],G[:,0,:]) #Nx4D\n",
    "        inH = att(G[:,0,:],H[:,0,:]) #Mx4D\n",
    "        \n",
    "        #maxpool concatenated tensors\n",
    "        maxpool_X = maxpool(N)\n",
    "        maxpool_Y = maxpool(M)\n",
    "        u = maxpool_X(inH.view(1,inH.data.shape[0],inH.data.shape[1],inH.data.shape[2]))  #1x1x2D\n",
    "        v = maxpool_Y(inG.view(1,inG.data.shape[0],inG.data.shape[1],inG.data.shape[2]))  #1x1x2D\n",
    "        \n",
    "        #feed forward neural network\n",
    "        NN = torch.cat((u,v),2).view(1,1,600)\n",
    "        NN = self.FF(NN)\n",
    "        NN = nn.functional.relu(NN)\n",
    "        output = self.out(NN)\n",
    "        return output\n",
    "\n",
    "dmodel = dnet(300,150,2000)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(dmodel.parameters(), lr=0.0002, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/u6676643/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0 loss :  53.20024871826172\n",
      "step :  1 loss :  45.00778579711914\n",
      "step :  2 loss :  37.44200134277344\n",
      "step :  3 loss :  32.07887268066406\n",
      "step :  4 loss :  29.65617561340332\n",
      "step :  5 loss :  30.462108612060547\n",
      "step :  6 loss :  36.53616714477539\n",
      "step :  7 loss :  42.295860290527344\n",
      "step :  8 loss :  49.38310623168945\n",
      "step :  9 loss :  43.633697509765625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x144fa8b20>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 10\n",
    "n_features = 300\n",
    "n_hidden = 100\n",
    "losslist = []\n",
    "for t in range(epochs):\n",
    "    for b in range(len(sol_data)):\n",
    "        solute = sol_data[b]\n",
    "        solvent = solv_data[0]\n",
    "        target = targets[b]  \n",
    "        output = dmodel(solute,solvent) \n",
    "        loss = criterion(output, target)  \n",
    "        losslist.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print('step : ' , t , 'loss : ' , loss.item())\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         526 function calls (518 primitive calls) in 0.078 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.078    0.078 {built-in method builtins.exec}\n",
      "        1    0.005    0.005    0.078    0.078 <string>:1(<module>)\n",
      "      9/1    0.000    0.000    0.073    0.073 module.py:715(_call_impl)\n",
      "        1    0.000    0.000    0.073    0.073 <ipython-input-208-c9036915f170>:23(forward)\n",
      "        2    0.000    0.000    0.070    0.035 rnn.py:555(forward)\n",
      "        2    0.069    0.035    0.069    0.035 {built-in method lstm}\n",
      "        2    0.000    0.000    0.002    0.001 <ipython-input-207-127204d06c41>:8(att)\n",
      "        2    0.001    0.000    0.001    0.001 <ipython-input-207-127204d06c41>:1(alpha)\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method exp}\n",
      "        2    0.000    0.000    0.000    0.000 <ipython-input-208-c9036915f170>:10(forward)\n",
      "        2    0.000    0.000    0.000    0.000 pooling.py:152(forward)\n",
      "        2    0.000    0.000    0.000    0.000 _jit_internal.py:257(fn)\n",
      "        2    0.000    0.000    0.000    0.000 functional.py:574(_max_pool2d)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method max_pool2d}\n",
      "        2    0.000    0.000    0.000    0.000 linear.py:92(forward)\n",
      "        2    0.000    0.000    0.000    0.000 functional.py:1669(linear)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'matmul' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 <ipython-input-208-c9036915f170>:7(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method cat}\n",
      "        4    0.000    0.000    0.000    0.000 module.py:223(__init__)\n",
      "       54    0.000    0.000    0.000    0.000 module.py:781(__setattr__)\n",
      "        2    0.000    0.000    0.000    0.000 pooling.py:17(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method zeros}\n",
      "        2    0.000    0.000    0.000    0.000 rnn.py:529(check_forward_args)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method pow}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method sum}\n",
      "        2    0.000    0.000    0.000    0.000 rnn.py:171(check_input)\n",
      "        1    0.000    0.000    0.000    0.000 functional.py:1124(relu)\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method t}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method relu}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "      112    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        2    0.000    0.000    0.000    0.000 {method 't' of 'torch._C._TensorBase' objects}\n",
      "      160    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "       10    0.000    0.000    0.000    0.000 module.py:765(__getattr__)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 overrides.py:1070(has_torch_function)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "       36    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "        2    0.000    0.000    0.000    0.000 _VF.py:25(__getattr__)\n",
      "        4    0.000    0.000    0.000    0.000 rnn.py:193(check_hidden_size)\n",
      "        6    0.000    0.000    0.000    0.000 overrides.py:1083(<genexpr>)\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        2    0.000    0.000    0.000    0.000 rnn.py:182(get_expected_hidden_size)\n",
      "        2    0.000    0.000    0.000    0.000 functional.py:1686(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        2    0.000    0.000    0.000    0.000 module.py:782(remove_from)\n",
      "        2    0.000    0.000    0.000    0.000 rnn.py:538(permute_hidden)\n",
      "        5    0.000    0.000    0.000    0.000 _jit_internal.py:750(is_scripting)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._C._is_torch_function_enabled}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"dmodel(X[2],Y[0])\", sort = \"cumtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch model definition\n",
    "epochs = 10\n",
    "n_features = 300\n",
    "n_hidden = 100\n",
    "batch_size = 32\n",
    "\n",
    "class maxpool(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(maxpool, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d((L,2), stride=2)\n",
    "    def forward(self, X):\n",
    "        return self.maxpool(X)\n",
    "\n",
    "class dnet(nn.Module):\n",
    "    def __init__(self, n_features, D, FF):\n",
    "        super(dnet, self).__init__()\n",
    "    \n",
    "        self.biLSTM_X = nn.LSTM(n_features, D, bidirectional=True)\n",
    "        self.biLSTM_Y = nn.LSTM(n_features, D, bidirectional=True)\n",
    "        \n",
    "        self.FF = nn.Linear(4*D, FF)\n",
    "        self.out = nn.Linear(FF, 1)\n",
    "    \n",
    "    def forward(self,X,Y):\n",
    "        N = X.data.shape[0]\n",
    "        M = Y.data.shape[0]\n",
    "        \n",
    "        #turn input list of vec into correct shape\n",
    "        X = X.view(X.data.shape[0],1,X.data.shape[1]) #N rows\n",
    "        Y = Y.view(Y.data.shape[0],1,Y.data.shape[1]) #M rows\n",
    "        \n",
    "        #biLSTM to get hidden states\n",
    "        H, hcX = self.biLSTM_X(X, None) #NxBx2D matrix\n",
    "        G, hcY = self.biLSTM_Y(Y, None) #MxBx2D matrix\n",
    "        \n",
    "        inG = torch.Tensor([att(G[:,b,:],H[:,b,:]) for b in range(batch_size)])\n",
    "        inH = torch.Tensor([att(H[:,b,:],G[:,b,:]) for b in range(batch_size)])\n",
    "        \n",
    "        #maxpool concatenated tensors\n",
    "        maxpool_X = maxpool(N)\n",
    "        maxpool_Y = maxpool(M)\n",
    "        u = maxpool_X(inH)  #1x1x2D\n",
    "        v = maxpool_Y(inG)  #1x1x2D\n",
    "        \n",
    "        #feed forward neural network\n",
    "        NN = torch.cat((u,v),2)\n",
    "        NN = self.FF(NN)\n",
    "        NN = nn.functional.relu(NN)\n",
    "        output = self.out(NN)\n",
    "        return output\n",
    "\n",
    "dmodel = dnet(300,150,2000)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(dmodel.parameters(), lr=0.0002, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SolvDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-af2b7c4c6e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollate_fn_padd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def collate_fn_padd(batch):\n",
    "    '''\n",
    "    Padds batch of variable length\n",
    "\n",
    "    note: it converts things ToTensor manually here since the ToTensor transform\n",
    "    assume it takes in images rather than arbitrary tensors.\n",
    "    '''\n",
    "    ## get sequence lengths\n",
    "    lengths = torch.tensor([ t.shape[0] for t in batch ]).to(device)\n",
    "    ## padd\n",
    "    batch = [ torch.Tensor(t).to(device) for t in batch ]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch)\n",
    "    ## compute mask\n",
    "    mask = (batch != 0).to(device)\n",
    "    return batch, lengths, mask\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn = collate_fn_padd)\n",
    "\n",
    "for batch_idx, (x, t) in enumerate(loader):\n",
    "    print(x.shape, t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(epochs):\n",
    "    for b in range(len(X)):\n",
    "        solute = X[b]\n",
    "        solvent = Y[0]\n",
    "        target = targets[b]  \n",
    "\n",
    "        output = dmodel(solute,solvent) \n",
    "        print(output)\n",
    "        loss = criterion(output, target)  \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        optimizer.zero_grad() \n",
    "    print('step : ' , t , 'loss : ' , loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

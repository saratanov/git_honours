{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data\n",
    "data = pd.read_csv('winequality-white.csv', delimiter=';')\n",
    "\n",
    "# try shuffle data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n_features = data.shape[1] - 1\n",
    "\n",
    "#preprocess normalise\n",
    "from sklearn.preprocessing import Normalizer\n",
    "norm = Normalizer()\n",
    "data.iloc[:, :n_features] = norm.fit_transform(data.iloc[:, :n_features])\n",
    "\n",
    "# randomly split data into training set (80%) and testing set (20%)\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train_data = data[msk]\n",
    "test_data = data[~msk]\n",
    "\n",
    "# split training data into input and target\n",
    "# the first columns are features, the last one is target\n",
    "train_input = train_data.iloc[:, :n_features]\n",
    "train_target = train_data.iloc[:, n_features]\n",
    "\n",
    "# split testing data into input and target\n",
    "# the first columns are features, the last one is target\n",
    "test_input = test_data.iloc[:, :n_features]\n",
    "test_target = test_data.iloc[:, n_features]\n",
    "\n",
    "# create Tensors to hold inputs and outputs\n",
    "X = torch.Tensor(train_input.values).float()\n",
    "Y = torch.Tensor(train_target.values).float()\n",
    "Y = torch.reshape(Y, (Y.shape[0],1))\n",
    "test_X = torch.Tensor(test_input.values).float()\n",
    "test_Y = torch.Tensor(test_target.values).float()\n",
    "test_Y = torch.reshape(test_Y, (test_Y.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "n_hidden = 5\n",
    "num_epochs = 501\n",
    "learning_rate = 0.01\n",
    "\n",
    "# define our regression model\n",
    "class Regression(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Regression, self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(input_size, hidden_size)   # hidden layer\n",
    "        self.hidden2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.predict = torch.nn.Linear(hidden_size, output_size)   # output layer\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))      # activation function for hidden layer\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.predict(x)                 # linear output\n",
    "        return x\n",
    "\n",
    "net = Regression(input_size=n_features, hidden_size=n_hidden, output_size=1)     # define the network\n",
    "\n",
    "# define loss function\n",
    "# Softmax is internally computed in nn.CrossEntropyLoss.\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "# define optimiser\n",
    "optimiser = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t =  0 training loss =  32.687530517578125 accuracy =  0.0\n",
      "t =  50 training loss =  3.274199962615967 accuracy =  33.231784716933234\n",
      "t =  100 training loss =  0.770240068435669 accuracy =  91.03833460269104\n",
      "t =  150 training loss =  0.7496514320373535 accuracy =  90.3021071337903\n",
      "t =  200 training loss =  0.7478443384170532 accuracy =  90.14978420919014\n",
      "t =  250 training loss =  0.745995283126831 accuracy =  90.35288144199035\n",
      "t =  300 training loss =  0.744113028049469 accuracy =  90.14978420919014\n",
      "t =  350 training loss =  0.7422428727149963 accuracy =  89.94668697638994\n",
      "t =  400 training loss =  0.7404181957244873 accuracy =  89.66742828128967\n",
      "t =  450 training loss =  0.7386618852615356 accuracy =  89.38816958618939\n",
      "t =  500 training loss =  0.7369887232780457 accuracy =  89.43894389438944\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store all losses for visualisation\n",
    "all_losses = []\n",
    "n_items = Y.shape[0]\n",
    "pct_close = 0.2\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    # pass input x and get prediction\n",
    "    prediction = net(X)\n",
    "\n",
    "    # calculate loss\n",
    "    loss = loss_func(prediction, Y)\n",
    "    all_losses.append(loss.item())\n",
    "\n",
    "    # clear gradients for next train\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # perform backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # call the step function on an Optimiser makes an update to its\n",
    "    # parameters\n",
    "    optimiser.step()\n",
    "\n",
    "    if t % 50 == 0:\n",
    "        n_correct = torch.sum((torch.abs(prediction - Y) < torch.abs(pct_close * Y)))\n",
    "        result = (n_correct.item() * 100.0 / n_items)\n",
    "        print(\"t = \",t,\"training loss = \",loss.item(), \"accuracy = \",result)\n",
    "        \n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.7469558715820312 accuracy =  89.05109489051095\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "net = net.eval()\n",
    "n_items = test_Y.shape[0]\n",
    "n_correct = torch.sum((torch.abs(net(test_X) - test_Y) < torch.abs(pct_close * test_Y)))\n",
    "result = (n_correct.item() * 100.0 / n_items)\n",
    "test_loss = loss_func(net(test_X), test_Y)\n",
    "print(\"loss = \", test_loss.item(), \"accuracy = \",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

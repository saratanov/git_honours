{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from deap import algorithms, base, creator, tools\n",
    "import copy\n",
    "import operator\n",
    "import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data\n",
    "data = pd.read_csv('SFEW.csv',  header=None, skiprows=1)\n",
    "\n",
    "# drop first column\n",
    "data.drop(data.columns[0], axis=1, inplace=True)\n",
    "\n",
    "#remove Nan PHOG descriptor pattern\n",
    "data.drop([205], axis=0, inplace=True)\n",
    "\n",
    "# try shuffle data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#normalisation of features\n",
    "for column in data:\n",
    "    if column == 1:\n",
    "        pass\n",
    "    else:\n",
    "        data[column] = data.loc[:, [column]].apply(lambda x: (x - x.mean()) / x.std())\n",
    "        \n",
    "# stratified 10-fold split into training set and testing set\n",
    "X = data.iloc[:,1:11].values\n",
    "Y = data.iloc[:,0].values-1\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "split_data = skf.split(X,Y)\n",
    "\n",
    "folded_data = []\n",
    "for train_index, test_index in split_data:\n",
    "    # Split train-test\n",
    "    X_train, X_test = torch.Tensor(X[train_index]), torch.Tensor(X[test_index])\n",
    "    Y_train, Y_test = torch.Tensor(Y[train_index]).long(), torch.Tensor(Y[test_index]).long()\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    folded_data.append([X_train,Y_train,X_test,Y_test,train_loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the three-layer neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        first = self.fc1(x)\n",
    "        act = self.sigmoid(first)\n",
    "        out = self.fc2(act)\n",
    "        return act, out  #outputs both the hidden layer activation matrix and the output classification\n",
    "    \n",
    "# define the loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to plot confusion matrix\n",
    "def plot_confusion(input_sample, num_classes, des_output, actual_output):\n",
    "    confusion = torch.zeros(num_classes, num_classes)\n",
    "    for i in range(input_sample):\n",
    "        actual_class = actual_output[i]\n",
    "        predicted_class = des_output[i]\n",
    "\n",
    "        confusion[actual_class][predicted_class] += 1\n",
    "\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training step for batch training\n",
    "def train_step(model, optimizer, loader):\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        X = batch_x\n",
    "        Y = batch_y.long()\n",
    "        _, outputs = model(X)\n",
    "        loss = criterion(outputs, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        return loss.item()\n",
    "\n",
    "# distinctiveness pruning step\n",
    "def prune(model, x, theta):\n",
    "    n_neu = model.fc1.weight.data.size(0) #initial number of neurons\n",
    "    activation, _ = model(x)\n",
    "    cos = nn.CosineSimilarity(dim=0, eps=1e-6) # calculates cosine similarity between column vectors\n",
    "    activation += torch.full(activation.size(), -0.5) #normalise activation vectors\n",
    "    keep = list(range(n_neu)) #generate list of column indices to keep track of neurons\n",
    "    for j in range(n_neu):\n",
    "        for k in range(j+1,n_neu):\n",
    "            angle = cos(activation[:,j],activation[:,k])\n",
    "            n_neu = model.fc1.weight.data.size(0)\n",
    "            if angle.item() >= math.cos(math.radians(theta)) and k in keep:  # similar neurons\n",
    "                model.fc1.weight.data[j] += model.fc1.weight.data[k]\n",
    "                model.fc1.bias.data[j] += model.fc1.bias.data[k]\n",
    "                model.fc2.weight.data[:,j] += model.fc2.weight.data[:,k] # adds together all weights and biases from k to j\n",
    "                keep.remove(k) #removes neuron k from list\n",
    "            if angle.item() <= math.cos(math.radians(180-theta)) and k in keep and j in keep: # complementary neurons\n",
    "                keep.remove(k) #removes neuron k and j from list\n",
    "                keep.remove(j)\n",
    "    model.fc1.weight.data = model.fc1.weight.data[keep]\n",
    "    model.fc2.weight.data = model.fc2.weight.data[:,keep] # removes all relevant weights and biases from the model\n",
    "    model.fc1.bias.data = model.fc1.bias.data[keep]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification accuracy\n",
    "def accuracy(model, X, Y):\n",
    "    _, outputs = model(X)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total = predicted.size(0)\n",
    "    correct = sum(predicted.data.numpy() == Y.data.numpy())\n",
    "    return 100*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classwise precision, recall, specificity matrix\n",
    "def plot_prs(inputs, num_classes, targets, outputs):\n",
    "    confusion = plot_confusion(inputs, num_classes, targets, outputs)\n",
    "    prs = torch.zeros(3, num_classes)\n",
    "    \n",
    "    def div(n, d):\n",
    "        if d == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return n / d\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        tp = confusion[i,i].item() # true postive\n",
    "        fp = (sum(confusion[:,i])-confusion[i,i]).item() #false positive\n",
    "        fn = (sum(confusion[i,:])-confusion[i,i]).item() #false negative\n",
    "        tn = targets.size(0)-tp-fp-fn #true negative\n",
    "        \n",
    "        prs[:,i] = torch.Tensor([div(tp,tp+fp),div(tp,tp+fn),div(tn,tn+fp)])\n",
    "    return prs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 1: neural network hyperparamaterisation\n",
    "\n",
    "# plots the accuracy v epoch graph of a regular neural network\n",
    "def normal_NN_graph(num_epoch, num_hidden, lr, data):\n",
    "    net = Net(10, num_hidden, 7)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        train_step(net, optimizer, data[4])\n",
    "        train_acc.append(accuracy(net, data[0], data[1]))\n",
    "        test_acc.append(accuracy(net, data[2], data[3])) #calculate accuracy at each epoch\n",
    "    \n",
    "    print('neurons:', num_hidden,', lr: ', lr)\n",
    "    print('Training Accuracy: %.2f %%' % accuracy(net, data[0], data[1]))\n",
    "    print('Testing Accuracy: %.2f %%' % accuracy(net, data[2], data[3]))\n",
    "\n",
    "    # plot accuracy v epoch\n",
    "    plt.figure()\n",
    "    plt.title('Classification accuracy during training')\n",
    "    plt.plot(train_acc, label=\"training\")\n",
    "    plt.plot(test_acc, label=\"testing\")\n",
    "    plt.xlabel('Training epoch')\n",
    "    plt.ylabel('Overall Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # plot PRS tensor\n",
    "    _, predicted = torch.max(test_out, 1)\n",
    "    print(plot_prs(data[2].shape[0], 7, predicted.long().data, data[3].data))\n",
    "    \n",
    "# calculate average testing accuracy for a normal neural network\n",
    "def normal_NN(num_epoch, num_hidden, lr):\n",
    "    test_acc = []\n",
    "    for data in folded_data: #cross-validation\n",
    "        net = Net(10, num_hidden, 7)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "        for epoch in range(num_epoch):\n",
    "            train_step(net, optimizer, data[4])\n",
    "        test_acc.append(accuracy(net, data[2], data[3]))\n",
    "    return np.mean(np.array(test_acc), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate testing accuracies for a variety of networks\n",
    "lr_list = [0.01,0.001,0.0001]\n",
    "hidden_list = [10,20,50,100,200,500,1000]\n",
    "\n",
    "opt_tensor = torch.Tensor([[normal_NN(300, h, lr) for h in hidden_list] for lr in lr_list])\n",
    "print(\"Hyperparameter testing:\")\n",
    "print(\"table of testing accuracies of networks with varying hidden neurons and learning rates\")\n",
    "print(opt_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision, recall, and specificity for 20 hidden neurons and a learning rate of 0.01 after 300 training epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2060, 0.1786, 0.2461, 0.2798, 0.3068, 0.2463, 0.2339],\n",
       "        [0.1600, 0.0839, 0.2633, 0.4500, 0.3000, 0.1500, 0.2200],\n",
       "        [0.8780, 0.9599, 0.8450, 0.7872, 0.8611, 0.9039, 0.8713]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate average PRS tensor\n",
    "def prs_plot_ave(num_epoch, num_hidden, lr):\n",
    "    prs_list = []\n",
    "    for data in folded_data:\n",
    "        net = Net(10, num_hidden, 7)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "        for epoch in range(num_epoch):\n",
    "            train_step(net, optimizer, data[4])\n",
    "        _, test_out = net(data[2])\n",
    "        _, predicted = torch.max(test_out, 1)\n",
    "        prs_list.append(plot_prs(data[2].shape[0], 7, predicted.long().data, data[3].data))\n",
    "    return torch.mean(torch.stack(prs_list), dim=0)\n",
    "\n",
    "print(\"Precision, recall, and specificity for 20 hidden neurons and a learning rate of 0.01 after 300 training epochs\")\n",
    "prs_plot_ave(300,20,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 2: pruned networks\n",
    "\n",
    "# collecting data about accuracy and number of neurons before and after pruning\n",
    "def neuron_pruning(data):\n",
    "    before_acc = []\n",
    "    after_acc = []\n",
    "    before_neuron = []\n",
    "    after_neuron = []\n",
    "    \n",
    "    for neuron in [20, 50, 100, 200, 500, 1000]:\n",
    "        net = Net(10,neuron,7)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), 0.01)\n",
    "\n",
    "        for epoch in range(300):\n",
    "            train_step(net, optimizer, data[4])\n",
    "            \n",
    "        before_neuron.append(neuron)\n",
    "        before_acc.append(accuracy(net, data[2], data[3]))\n",
    "\n",
    "        prune(net, data[0], 15)\n",
    "        after_neuron.append(net.fc1.weight.data.size(0))\n",
    "        after_acc.append(accuracy(net, data[2], data[3]))\n",
    "    \n",
    "    return torch.Tensor([before_acc, after_acc, before_neuron, after_neuron])\n",
    "\n",
    "# 10-fold cross validation - run 5 times and averaged\n",
    "part2_data = []\n",
    "for x in range(5):\n",
    "    for data in folded_data:\n",
    "        part2_data.append(neuron_pruning(data))\n",
    "part2_data = torch.mean(torch.stack(part2_data), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure\n",
    "#plt.title('Number of hidden neurons pruned')\n",
    "plt.plot(part2_data[2], part2_data[3], 'bo')\n",
    "plt.plot(part2_data[2], part2_data[3])\n",
    "plt.xlabel('Initial number of neurons')\n",
    "plt.ylabel('Final number of neurons')\n",
    "plt.show()\n",
    "\n",
    "plt.figure\n",
    "#plt.title('Network accuracy before and after distinctiveness pruning')\n",
    "plt.plot(part2_data[2], part2_data[0], 'bo', label = 'before')\n",
    "plt.plot(part2_data[2], part2_data[0])\n",
    "plt.plot(part2_data[2], part2_data[1])\n",
    "plt.plot(part2_data[2], part2_data[1], 'ro', label = 'after')\n",
    "plt.legend()\n",
    "plt.xlabel('Initial number of neurons')\n",
    "plt.ylabel('Overall Accuracy (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 3: distinctiveness threshold\n",
    "\n",
    "# collect data of final number of neurons and testing accuracy based on theta (distinctiveness threshold)\n",
    "def theta_pruning(data):\n",
    "    test_acc = []\n",
    "    theta_list = []\n",
    "    final_neurons = []\n",
    "\n",
    "    net = Net(10,100,7)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), 0.01)\n",
    "    \n",
    "    for epoch in range(300):\n",
    "        train_step(net, optimizer, data[4])\n",
    "    \n",
    "    for theta in range(0,95,5):\n",
    "        model = copy.deepcopy(net) #make a copy of the net for each theta angle\n",
    "        prune(model, data[0], theta)\n",
    "        theta_list.append(theta)\n",
    "        final_neurons.append(100-model.fc1.weight.data.size(0))\n",
    "        test_acc.append(accuracy(model, data[2], data[3]))\n",
    "    \n",
    "    return torch.Tensor([theta_list, final_neurons, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold cross validation - run 5 times and averaged\n",
    "part3_data = []\n",
    "for x in range(5):\n",
    "    for data in folded_data:\n",
    "        part3_data.append(theta_pruning(data))\n",
    "part3_data = torch.mean(torch.stack(part3_data), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Threshold angle (degrees)')\n",
    "ax1.set_ylabel('Overall Accuracy (%)', color=color)\n",
    "ax1.plot(part3_data[0], part3_data[2], 'ro')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Proportion of neurons pruned (%)', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(part3_data[0], part3_data[1], 'bo')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 4: genetic algorithm\n",
    "\n",
    "#genetic algorithm hyperparameter testing\n",
    "def evaluation(individual, net, data, N, lam, f):\n",
    "    model = copy.deepcopy(net)\n",
    "    #turn chromosome into keep list\n",
    "    keep = [i for i, x in enumerate(individual) if x == 1]\n",
    "    #keep hidden neurons in model, remove all others\n",
    "    model.fc1.weight.data = model.fc1.weight.data[keep]\n",
    "    model.fc2.weight.data = model.fc2.weight.data[:,keep] # removes all relevant weights and biases from the model\n",
    "    model.fc1.bias.data = model.fc1.bias.data[keep]\n",
    "    #check fitness\n",
    "    if f==0:\n",
    "        fitness = accuracy(model, data[0], data[1]) - lam*len(keep)/N\n",
    "    if f==1:\n",
    "        fitness = accuracy(model, data[0], data[1]) - lam*len(keep)\n",
    "    return [fitness]\n",
    "\n",
    "def GA_accuracy(individual, net, data, N):\n",
    "    model = copy.deepcopy(net)\n",
    "    #turn chromosome into keep list\n",
    "    keep = [i for i, x in enumerate(individual) if x == 1]\n",
    "    #keep hidden neurons in model, remove all others\n",
    "    model.fc1.weight.data = model.fc1.weight.data[keep]\n",
    "    model.fc2.weight.data = model.fc2.weight.data[:,keep] # removes all relevant weights and biases from the model\n",
    "    model.fc1.bias.data = model.fc1.bias.data[keep]\n",
    "    #check fitness\n",
    "    train_acc = accuracy(model, data[0], data[1])\n",
    "    test_acc = accuracy(model, data[2], data[3])\n",
    "    return train_acc, test_acc\n",
    "\n",
    "def GA(net, N, lam, f, data):\n",
    "    toolbox = base.Toolbox()\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, N)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)\n",
    "    toolbox.register(\"evaluate\", lambda x: evaluation(x, net, data, N, lam, f))\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "    hof = tools.HallOfFame(5)\n",
    "    pop = toolbox.population(n=100)\n",
    "    \n",
    "    fit_stats = tools.Statistics(key=operator.attrgetter(\"fitness.values\"))\n",
    "    fit_stats.register('mean', np.mean)\n",
    "    fit_stats.register('max', np.max)\n",
    "    result, log = algorithms.eaSimple(toolbox.population(n=100), toolbox, cxpb=0.8, mutpb=0.2, ngen=50, halloffame=hof, verbose=False,\n",
    "                                      stats=fit_stats)\n",
    "    \n",
    "    best_individual = tools.selBest(result, k=1)[0]\n",
    "    best_keep = [i for i, x in enumerate(best_individual) if x == 1]\n",
    "    f_train, f_test = GA_accuracy(best_individual, net, data, N)\n",
    "    f_N = len(best_keep)\n",
    "    f_N_perc = len(best_keep)/N*100\n",
    "    return f_train, f_test, f_N, f_N_perc\n",
    "\n",
    "def GA_func(N_list, lam_list, f, data):\n",
    "    N_data = []\n",
    "    for N in N_list:\n",
    "        net = Net(10, N, 7)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "        for epoch in range(300):\n",
    "            train_step(net, optimizer, data[4])\n",
    "        i_train = accuracy(net, data[0], data[1])\n",
    "        i_test = accuracy(net, data[2], data[3])\n",
    "        \n",
    "        lam_data = []\n",
    "        for lam in lam_list:\n",
    "            f_train, f_test, f_N, f_N_perc = GA(net, N, lam, f, data)\n",
    "            lam_data.append([N, lam, i_train, i_test, f_train, f_test, f_N, f_N_perc])\n",
    "        N_data.append(np.array(lam_data))\n",
    "    \n",
    "    return np.stack(N_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/u6676643/opt/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/Users/u6676643/opt/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-26df1aa2701c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhyp_data_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolded_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mhyp_data_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGA_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam_list_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mhyp_data_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp_data_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-2c14636e64c2>\u001b[0m in \u001b[0;36mGA_func\u001b[0;34m(N_list, lam_list, f, data)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mlam_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlam_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_N_perc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mlam_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_N_perc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mN_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-2c14636e64c2>\u001b[0m in \u001b[0;36mGA\u001b[0;34m(net, N, lam, f, data)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mfit_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mfit_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     result, log = algorithms.eaSimple(toolbox.population(n=100), toolbox, cxpb=0.8, mutpb=0.2, ngen=50, halloffame=hof, verbose=False,\n\u001b[0m\u001b[1;32m     50\u001b[0m                                       stats=fit_stats)\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/deap/algorithms.py\u001b[0m in \u001b[0;36meaSimple\u001b[0;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0minvalid_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moffspring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-2c14636e64c2>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcxOnePoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mutate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutFlipBit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindpb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselTournament\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtournsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mhof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHallOfFame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-2c14636e64c2>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(individual, net, data, N, lam, f)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#genetic algorithm hyperparameter testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#turn chromosome into keep list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/parameter.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_list = [20,50,100,200,500]\n",
    "lam_list_0 = [-5,-2.5,-1,0,1,2,3,4,5,10,20]\n",
    "\n",
    "# 10-fold cross validation - run 5 times and averaged\n",
    "hyp_data_0 = []\n",
    "for data in folded_data:\n",
    "    hyp_data_0.append(GA_func(N_list, lam_list_0, 0, data))\n",
    "hyp_data_0 = np.mean(np.array(hyp_data_0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 4))\n",
    "for i in range(len(N_list)):\n",
    "    plt.plot(lam_list_0, hyp_data_0[i,:,5], label=str(hyp_data_0[i,0,0])+' neurons')\n",
    "plt.legend()\n",
    "plt.ylabel('Final testing accuracy'); plt.xlabel('Lambda');\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "for i in range(len(N_list)):\n",
    "    plt.plot(lam_list_0, hyp_data_0[i,:,4], label=str(hyp_data_0[i,0,0])+' neurons')\n",
    "plt.legend()\n",
    "plt.ylabel('Final training accuracy'); plt.xlabel('Lambda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_list = [20,50,100,200,500]\n",
    "lam_list_1 = [0,0.1,0.25,0.5,0.75,1,2]\n",
    "\n",
    "# 10-fold cross validation - run 5 times and averaged\n",
    "hyp_data_1 = []\n",
    "for data in folded_data:\n",
    "    hyp_data_1.append(GA_func(N_list, lam_list_1, 0, data))\n",
    "hyp_data_1 = np.mean(np.array(hyp_data_1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 4))\n",
    "for i in range(len(N_list)):\n",
    "    plt.plot(lam_list_1, hyp_data_1[i,:,5], label=str(hyp_data_1[i,0,0])+' neurons')\n",
    "plt.legend()\n",
    "plt.ylabel('Final testing accuracy'); plt.xlabel('Lambda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 5: comparison of pruning techniques\n",
    "\n",
    "def prune_step(net, data, theta):\n",
    "    model = prune(copy.deepcopy(net), data[0], theta)\n",
    "    test_acc = accuracy(model, data[2], data[3])\n",
    "    f_N = model.fc1.weight.data.size(0)\n",
    "    return test_acc, f_N\n",
    "\n",
    "def comparison_func(N_list, data):\n",
    "    N_data = []\n",
    "    for i_N in N_list:\n",
    "        net = Net(10, i_N, 7)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "        for epoch in range(300):\n",
    "            train_step(net, optimizer, data[4])\n",
    "        i_test = accuracy(net, data[2], data[3])\n",
    "        \n",
    "        _, GA_test, GA_N, _ = GA(net, i_N, 2, 0, data)\n",
    "        p15_test, p15_N = prune_step(net, data, 15)\n",
    "        p40_test, p40_N = prune_step(net, data, 40)\n",
    "        N_data.append([i_N, i_test, GA_N, GA_test, p15_N, p15_test, p40_N, p15_test])\n",
    "        print(i_N)\n",
    "    return np.array(N_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "50\n",
      "100\n",
      "200\n",
      "500\n",
      "ye\n",
      "20\n",
      "50\n",
      "100\n",
      "200\n",
      "500\n",
      "ye\n",
      "20\n",
      "50\n",
      "100\n",
      "200\n",
      "500\n",
      "ye\n",
      "20\n",
      "50\n",
      "100\n",
      "200\n",
      "500\n",
      "ye\n",
      "20\n",
      "50\n",
      "100\n",
      "200\n",
      "500\n",
      "ye\n",
      "20\n",
      "50\n",
      "100\n",
      "200\n",
      "500\n",
      "ye\n",
      "20\n",
      "50\n",
      "100\n",
      "200\n",
      "500\n",
      "ye\n",
      "20\n",
      "50\n",
      "100\n",
      "200\n",
      "500\n",
      "ye\n",
      "20\n",
      "50\n",
      "100\n",
      "200\n",
      "500\n",
      "ye\n",
      "20\n",
      "50\n",
      "100\n",
      "200\n",
      "500\n",
      "ye\n"
     ]
    }
   ],
   "source": [
    "N_list_comp = [20,50,100,200,500]\n",
    "\n",
    "# 10-fold cross validation\n",
    "comp_data = []\n",
    "for data in folded_data:\n",
    "    comp_data.append(comparison_func(N_list_comp, data))\n",
    "    print('ye')\n",
    "comp_data = np.mean(np.array(comp_data), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing accuracies for each method vs initial hidden size\n",
    "#final hidden size vs initial hidden size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Configure Everything We Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict as ddict, OrderedDict as odict\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from rdkit.Chem import PandasTools, AllChem as Chem, Descriptors\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "import deepchem as dc\n",
    "import torch\n",
    "\n",
    "from rdkit import RDLogger\n",
    "\n",
    "RDLogger.DisableLog('rdApp.*') \n",
    "\n",
    "import basic as b\n",
    "import chemprop_ish as c\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)  # Display floats without scientific notation\n",
    "\n",
    "# In many cases NaN\n",
    "not_used_desc = ['MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge']\n",
    "\n",
    "# Create a descriptor calculator for all RDKit descriptors except the ones above\n",
    "desc_calc = MolecularDescriptorCalculator([x for x in [x[0] for x in Descriptors.descList] if x not in not_used_desc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Loading Precombined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('combisolv_exp2.csv')\n",
    "solute = data['smiles_solute'].tolist()\n",
    "solvent = data['smiles_solvent'].tolist()\n",
    "pka = data['dGsolv_avg [kcal/mol]'].tolist()\n",
    "sol_solv = [[x,y] for x,y in zip(solute,solvent)]\n",
    "#preprocess pka too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_list = []\n",
    "for x in range(len(sol_solv)):\n",
    "    if sol_solv[x][0] in [\"[H][H]\",\"[2H][2H]\",\"[HH]\"]:\n",
    "        H_list.append(x)\n",
    "for x in sorted(H_list, reverse = True):\n",
    "    del sol_solv[x]\n",
    "    del pka[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_solv_mol = [[Chem.MolFromSmiles(x) for x in y] for y in sol_solv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8700"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sol_solv_mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for mols with 0 heavy atoms\n",
    "for x in sol_solv_mol:\n",
    "    for y in x:\n",
    "        if y.GetNumHeavyAtoms() == 0:\n",
    "            print(Chem.MolToSmiles(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Descriptors and Fingerprints\n",
    "- 196/200 RDKit descriptors\n",
    "- Morgan FP with radius=3 and useFeatures=True (FMorgan3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "descs, fmorgan3, descs_fmorgan3 = b.calc_xy_data(sol_solv_mol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Random Forest, Support Vector Machine (two configurations) and Multilayer Perceptron (three configurations)\n",
    "#### Using the following training sets with 5-fold cross-validation (shuffled)\n",
    "1. RDKit descriptor set\n",
    "2. FMorgan3\n",
    "3. RDKit descriptor set + FMorgan3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 24\n",
    "\n",
    "est_jobs = 12\n",
    "verbose = False\n",
    "\n",
    "y_data = np.array(pka)\n",
    "desc_sets = [[descs, 'Desc'],[fmorgan3, 'FMorgan3'],[descs_fmorgan3, 'Desc_FMorgan3']]\n",
    "\n",
    "models = ddict(odict)  # estimator => training set => [model, scaler]\n",
    "\n",
    "def train_all_sets(est_cls, params, name, torch_model):\n",
    "    for x_data, set_name in desc_sets:\n",
    "        models[name][set_name] = b.train_cv_model(est_cls, x_data, y_data, params, seed, torch_model=torch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_score_board(name):\n",
    "    print(f'{name} CV Scores:')\n",
    "    for ts, m in models[name].items():\n",
    "        print(f'\\t{ts}')\n",
    "        for k, v in m.cv_scores.items():\n",
    "            print(f'\\t\\t- {k}: {np.mean(v):.3f} ± {np.std(v):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### RandomForest (n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest (n_estimators=1000) CV Scores:\n",
      "\tDesc\n",
      "\t\t- mean_absolute_error: 0.314 ± 0.008\n",
      "\t\t- rmse: 0.671 ± 0.034\n",
      "\t\t- r2_score: 0.978 ± 0.002\n",
      "\tFMorgan3\n",
      "\t\t- mean_absolute_error: 0.717 ± 0.022\n",
      "\t\t- rmse: 1.380 ± 0.049\n",
      "\t\t- r2_score: 0.907 ± 0.006\n",
      "\tDesc_FMorgan3\n",
      "\t\t- mean_absolute_error: 0.314 ± 0.008\n",
      "\t\t- rmse: 0.672 ± 0.036\n",
      "\t\t- r2_score: 0.978 ± 0.002\n"
     ]
    }
   ],
   "source": [
    "est_cls = RandomForestRegressor\n",
    "rf_params = dict(n_estimators=1000, n_jobs=est_jobs, verbose=verbose, random_state=seed)\n",
    "name = 'RandomForest (n_estimators=1000)'\n",
    "\n",
    "train_all_sets(est_cls, rf_params, name, False)\n",
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### SupportVectorMachine (gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SupportVectorMachine (gamma=\"scale\") CV Scores:\n",
      "\tDesc\n",
      "\t\t- mean_absolute_error: 3.095 ± 0.054\n",
      "\t\t- rmse: 4.689 ± 0.079\n",
      "\t\t- r2_score: -0.073 ± 0.014\n",
      "\tFMorgan3\n",
      "\t\t- mean_absolute_error: 0.938 ± 0.017\n",
      "\t\t- rmse: 1.918 ± 0.059\n",
      "\t\t- r2_score: 0.820 ± 0.009\n",
      "\tDesc_FMorgan3\n",
      "\t\t- mean_absolute_error: 3.095 ± 0.054\n",
      "\t\t- rmse: 4.689 ± 0.079\n",
      "\t\t- r2_score: -0.073 ± 0.014\n"
     ]
    }
   ],
   "source": [
    "est_cls = SVR\n",
    "svr_params = dict(cache_size=4096, verbose=verbose)\n",
    "name = 'SupportVectorMachine (gamma=\"scale\")'\n",
    "\n",
    "train_all_sets(est_cls, svr_params, name, False)\n",
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### SupportVectorMachine (gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SupportVectorMachine (gamma=\"auto\") CV Scores:\n",
      "\tDesc\n",
      "\t\t- mean_absolute_error: 2.929 ± 0.057\n",
      "\t\t- rmse: 4.541 ± 0.087\n",
      "\t\t- r2_score: -0.007 ± 0.018\n",
      "\tFMorgan3\n",
      "\t\t- mean_absolute_error: 2.659 ± 0.045\n",
      "\t\t- rmse: 4.111 ± 0.075\n",
      "\t\t- r2_score: 0.175 ± 0.013\n",
      "\tDesc_FMorgan3\n",
      "\t\t- mean_absolute_error: 1.210 ± 0.047\n",
      "\t\t- rmse: 2.613 ± 0.103\n",
      "\t\t- r2_score: 0.667 ± 0.019\n"
     ]
    }
   ],
   "source": [
    "est_cls = SVR\n",
    "svr_params = dict(cache_size=4096, verbose=verbose, gamma='auto')\n",
    "name = 'SupportVectorMachine (gamma=\"auto\")'\n",
    "\n",
    "train_all_sets(est_cls, svr_params, name, False)\n",
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Multi Layer Perceptron (early_stopping=False, hidden_layer_sizes=(500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Layer Perceptron (early_stopping=False, hidden_layer_sizes=(500, 500)) CV Scores:\n",
      "\tDesc\n",
      "\t\t- mean_absolute_error: 164906611.176 ± 181177898.511\n",
      "\t\t- rmse: 1609817340.697 ± 1790354766.720\n",
      "\t\t- r2_score: -280813531084887296.000 ± 352954091191318848.000\n",
      "\tFMorgan3\n",
      "\t\t- mean_absolute_error: 0.661 ± 0.028\n",
      "\t\t- rmse: 1.272 ± 0.068\n",
      "\t\t- r2_score: 0.921 ± 0.008\n",
      "\tDesc_FMorgan3\n",
      "\t\t- mean_absolute_error: 76720537.574 ± 60967739.463\n",
      "\t\t- rmse: 779932876.426 ± 630328309.503\n",
      "\t\t- r2_score: -49246725664475824.000 ± 50634856180989016.000\n"
     ]
    }
   ],
   "source": [
    "est_cls = MLPRegressor\n",
    "mlp_params = dict(hidden_layer_sizes=(500, 500), verbose=verbose, random_state=seed)\n",
    "name = 'Multi Layer Perceptron (early_stopping=False, hidden_layer_sizes=(500, 500))'\n",
    "\n",
    "train_all_sets(est_cls, mlp_params, name, False)\n",
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/u6676643/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:587: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MLPRegressor' object has no attribute '_best_coefs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-b84c4702758c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(500, 500))'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_all_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mgenerate_score_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-dfb802814e32>\u001b[0m in \u001b[0;36mtrain_all_sets\u001b[0;34m(est_cls, params, name, torch_model)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_all_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdesc_sets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_cv_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/codes/diympnn/deepchemMPNN/basic.py\u001b[0m in \u001b[0;36mtrain_cv_model\u001b[0;34m(est_cls, x_data, y_data, params, random_state, cv, shuffle, torch_model, scoring_funcs)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;34m\"\"\"Trains a cross-validated model\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch_model\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mcvr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCV_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mest_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mcvr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring_funcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring_funcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codes/diympnn/deepchemMPNN/basic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_data, y_data, scoring_funcs, random_state)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;31m# Fit k models and store them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \"\"\"\n\u001b[0;32m--> 641\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;31m# Run the Stochastic optimization solver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_STOCHASTIC_SOLVERS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             self._fit_stochastic(X, y, activations, deltas, coef_grads,\n\u001b[0m\u001b[1;32m    371\u001b[0m                                  intercept_grads, layer_units, incremental)\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_stochastic\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units, incremental)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0;31m# restore best weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_best_coefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_best_intercepts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLPRegressor' object has no attribute '_best_coefs'"
     ]
    }
   ],
   "source": [
    "est_cls = MLPRegressor\n",
    "mlp_params = dict(hidden_layer_sizes=(500, 500), verbose=verbose, random_state=seed, early_stopping=True)\n",
    "name = 'Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(500, 500))'\n",
    "\n",
    "train_all_sets(est_cls, mlp_params, name, False)\n",
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(250, 250, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(250, 250, 250)) CV Scores:\n",
      "\tDesc\n",
      "\t\t- mean_absolute_error: 4165369.456 ± 6817569.897\n",
      "\t\t- rmse: 38747282.618 ± 61925880.287\n",
      "\t\t- r2_score: -257493886094999.188 ± 491086682662495.438\n",
      "\tFMorgan3\n",
      "\t\t- mean_absolute_error: 0.677 ± 0.033\n",
      "\t\t- rmse: 1.251 ± 0.043\n",
      "\t\t- r2_score: 0.923 ± 0.005\n",
      "\tDesc_FMorgan3\n",
      "\t\t- mean_absolute_error: 116006.029 ± 229890.703\n",
      "\t\t- rmse: 1010317.069 ± 1998715.688\n",
      "\t\t- r2_score: -237141818932.427 ± 474254063249.370\n"
     ]
    }
   ],
   "source": [
    "est_cls = MLPRegressor\n",
    "mlp_params = dict(hidden_layer_sizes=(250, 250, 250), verbose=verbose, random_state=seed, early_stopping=True)\n",
    "name = 'Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(250, 250, 250))'\n",
    "\n",
    "train_all_sets(est_cls, mlp_params, name, False)\n",
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### XGradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGradientBoost CV Scores:\n",
      "\tDesc\n",
      "\t\t- mean_absolute_error: 0.301 ± 0.004\n",
      "\t\t- rmse: 0.614 ± 0.041\n",
      "\t\t- r2_score: 0.982 ± 0.002\n",
      "\tFMorgan3\n",
      "\t\t- mean_absolute_error: 0.870 ± 0.027\n",
      "\t\t- rmse: 1.429 ± 0.043\n",
      "\t\t- r2_score: 0.900 ± 0.006\n",
      "\tDesc_FMorgan3\n",
      "\t\t- mean_absolute_error: 0.335 ± 0.010\n",
      "\t\t- rmse: 0.643 ± 0.045\n",
      "\t\t- r2_score: 0.980 ± 0.003\n"
     ]
    }
   ],
   "source": [
    "est_cls = xgb.XGBRegressor\n",
    "xgb_params = dict(verbosity=2 if verbose else 0, random_state=seed, n_jobs=est_jobs)\n",
    "name = 'XGradientBoost'\n",
    "\n",
    "train_all_sets(est_cls, xgb_params, name, False)\n",
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training torch models\n",
    "#### Using the following training sets with 5-fold cross-validation (shuffled)\n",
    "1. Sol / solvent pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Torch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 24\n",
    "verbose = False\n",
    "\n",
    "y_data = torch.Tensor(pka)\n",
    "x_data = sol_solv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_cv_model() missing 1 required positional argument: 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-60909d8245e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'MPNN'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_cv_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mgenerate_score_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: train_cv_model() missing 1 required positional argument: 'random_state'"
     ]
    }
   ],
   "source": [
    "args = c.TrainArgs()\n",
    "args.__dict__.update({\"depth\":3, \"dropout\":0.2})\n",
    "est_cls = c.double_MPNN(args)\n",
    "name = 'MPNN'\n",
    "\n",
    "b.train_cv_model(est_cls, x_data, y_data, random_state=seed)\n",
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

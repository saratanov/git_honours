{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Configure Everything We Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict as ddict, OrderedDict as odict\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from rdkit.Chem import PandasTools, AllChem as Chem, Descriptors\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "import torch\n",
    "import deepchem as dc\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)  # Display floats without scientific notation\n",
    "\n",
    "# In many cases NaN\n",
    "not_used_desc = ['MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge']\n",
    "\n",
    "# Create a descriptor calculator for all RDKit descriptors except the ones above\n",
    "desc_calc = MolecularDescriptorCalculator([x for x in [x[0] for x in Descriptors.descList] if x not in not_used_desc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Cross-Validation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVRegressor:\n",
    "    \"\"\"\n",
    "    Regressor that predicts based on predictions of k models from k-fold CV.\n",
    "    Accepts any Scikit-learn-like regressor as base regressor. It trains k models\n",
    "    by doing k-fold CV and stores the individual models. Predictions\n",
    "    on new samples are done by calculating mean predictions from all models.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    est : Any\n",
    "        Scikit-learn (-like) regressor object. Must contain .fit() and .predict() methods.\n",
    "    params : Dict[str, Any]\n",
    "        Regressor parameters\n",
    "    n_folds : int\n",
    "        Number of folds for k-fold\n",
    "    shuffle : bool\n",
    "        Shuffling of data for CV\n",
    "    \"\"\"\n",
    "    __slots__ = ('est', 'params', 'models', 'n_folds', 'shuffle', 'cv_scores')\n",
    "\n",
    "    def __init__(self, est: Any, params: Dict[str, Any], n_folds: int = 5, shuffle: bool = True, num_epochs: int = 10):\n",
    "        self.est = est\n",
    "        self.params = params\n",
    "        self.models = []\n",
    "        self.n_folds = n_folds\n",
    "        self.shuffle = shuffle\n",
    "        self.cv_scores = ddict(list)\n",
    "        self.num_epochs = num_epochs\n",
    "        \n",
    "    def train_func(self, model, x_data: torch.Tensor, y_data: torch.Tensor):\n",
    "        dataset = torch.utils.data.TensorDataset(x_data, y_data)\n",
    "        trainloader = torch.utils.data.DataLoader(dataset, batch_size=5)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "        for epoch in range(0, self.num_epochs):\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, targets = data\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return model\n",
    "            \n",
    "    def fit(self, x_data: torch.Tensor, y_data: torch.Tensor, scoring_funcs: List=(), random_state: int=None) -> None:\n",
    "        \"\"\"\n",
    "        Build a regressor consisting of k-models.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x_data : torch.tensor\n",
    "            Training data\n",
    "        y_data : torch.tensor\n",
    "            Target values\n",
    "        scoring_funcs : list\n",
    "            List of scoring functions to use for evaluating cross-validation results\n",
    "        random_state : int\n",
    "            Integer to use for seeding the k-fold split\n",
    "        \"\"\"\n",
    "\n",
    "        kf = KFold(n_splits=self.n_folds, shuffle=self.shuffle, random_state=random_state)\n",
    "        kf = kf.split(X=x_data, y=y_data)\n",
    "\n",
    "        # Fit k models and store them\n",
    "        for train_index, test_index in kf:\n",
    "            est_trained = train_func(self.est(**self.params), x_data[train_index], y_data[train_index])\n",
    "            if scoring_funcs:\n",
    "                test_pred = est_trained(x_data[test_index])\n",
    "                for sf in scoring_funcs:\n",
    "                    self.cv_scores[str(sf).split(' ')[1]].append(sf(y_data[test_index], test_pred))\n",
    "            self.models.append(est_trained)\n",
    "\n",
    "    def predict(self, x_data: torch.Tensor) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict using prediction mean from k models.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x_data : torch.Tensor\n",
    "            Samples to predict\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Predicted values\n",
    "        \"\"\"\n",
    "\n",
    "        return np.mean([m(x_data) for m in self.models], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Helpful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Helper function\"\"\"\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "def calc_stats_str(pka1, pka2):\n",
    "    \"\"\"Calculates R², MAE and RMSE for two iterables of floats or integers\"\"\"\n",
    "    assert len(pka1) == len(pka2), \"Both iterables must have the same length\"\n",
    "    return f'R²: {r2_score(pka1, pka2):.3f}\\n' \\\n",
    "           f'MAE: {mean_absolute_error(pka1, pka2):.3f}\\n' \\\n",
    "           f'RMSE: {rmse(pka1, pka2):.3f}'\n",
    "\n",
    "def train_cv_model(est_cls, x_data, y_data, params, random_state,\n",
    "                   cv=5, shuffle=True, scaled=False, scoring_funcs=(mean_absolute_error, rmse, r2_score)):\n",
    "    \"\"\"Scales the training data if wanted and trains a cross-validated model\"\"\"\n",
    "    scaler = None\n",
    "    if scaled:\n",
    "        scaler = StandardScaler()\n",
    "        x_data = scaler.fit_transform(x_data)\n",
    "    cvr = CVRegressor(est=est_cls, params=params, n_folds=cv, shuffle=shuffle)\n",
    "    cvr.fit(x_data, y_data, scoring_funcs=scoring_funcs, random_state=random_state)\n",
    "    return cvr, scaler\n",
    "\n",
    "def calc_x_data(solute,solvent):\n",
    "    fmorgan3 = [] \n",
    "    featurizer = dc.feat.CircularFingerprint(size=4096, radius=3)\n",
    "    X = featurizer.featurize(solute)\n",
    "    Y = featurizer.featurize(solvent)\n",
    "    fmorgan3 = torch.Tensor(np.concatenate((X,Y),axis=1))\n",
    "    return fmorgan3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOLECULAR REPS\n",
    "def mol_rep_data(sol_data,solv_data,rep):\n",
    "    if rep == 'ECFP':\n",
    "        featurizer = dc.feat.CircularFingerprint(size=1024, radius=3)\n",
    "        sol_rep = featurizer.featurize(solute)\n",
    "        solv_rep = featurizer.featurize(solvent)\n",
    "    if rep == 'desc':\n",
    "        featurizer = dc.feat.RDKitDescriptors()\n",
    "        sol_rep = featurizer.featurize(solute)\n",
    "        solv_rep = featurizer.featurize(solvent)\n",
    "    if rep == 'mol2vec':\n",
    "        #\n",
    "    return sol_rep,solv_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Loading Precombined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC1=C(C=C(C=C1)C(=O)O)C\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.read_csv('data/ETMdata.csv')\n",
    "all_df['solute2'] = all_df.apply(lambda x: Chem.MolFromSmiles(x['solute']), axis=1)\n",
    "all_df['solvent2'] = all_df.apply(lambda x: Chem.MolFromSmiles(x['solvent']), axis=1)\n",
    "print(all_df['solute'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Descriptors and Fingerprints\n",
    "- 196/200 RDKit descriptors\n",
    "- Morgan FP with radius=3 and useFeatures=True (FMorgan3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmorgan3 = calc_x_data(all_df['solute'],all_df['solvent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 8192])\n"
     ]
    }
   ],
   "source": [
    "print(fmorgan3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Random Forest, Support Vector Machine (two configurations) and Multilayer Perceptron (three configurations)\n",
    "#### Using the following training sets with 5-fold cross-validation (shuffled)\n",
    "1. RDKit descriptor set\n",
    "2. FMorgan3\n",
    "3. RDKit descriptor set + FMorgan3\n",
    "4. RDKit descriptor set (standard scaled)\n",
    "5. FMorgan3 (standard scaled)\n",
    "6. RDKit descriptor set + FMorgan3 (standard scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 24\n",
    "\n",
    "est_jobs = 12\n",
    "verbose = False\n",
    "\n",
    "y_train = all_df['pka']\n",
    "desc_sets = [fmorgan3]\n",
    "'''\n",
    "desc_sets = list(zip([descs, fmorgan3, descs_fmorgan3] * 2, \n",
    "                     [False] * 3 + [True] * 3, \n",
    "                     ['Desc', 'FMorgan3', 'Desc_FMorgan3', 'Desc_scaled', 'FMorgan3_scaled', 'Desc_FMorgan3_scaled']))\n",
    "                     '''\n",
    "\n",
    "models = ddict(odict)  # estimator => training set => [model, scaler]\n",
    "\n",
    "def train_all_sets(est_cls, params, name):\n",
    "    for x_data, scaled, set_name in desc_sets:\n",
    "        models[name][set_name] = train_cv_model(est_cls, x_data, y_train, params, seed, scaled=scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_score_board(name):\n",
    "    print(f'{name} CV Scores:')\n",
    "    for ts, (m, s) in models[name].items():\n",
    "        print(f'\\t{ts}')\n",
    "        for k, v in m.cv_scores.items():\n",
    "            print(f'\\t\\t- {k}: {np.mean(v):.3f} ± {np.std(v):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### RandomForest (n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = RandomForestRegressor\n",
    "rf_params = dict(n_estimators=1000, n_jobs=est_jobs, verbose=verbose, random_state=seed)\n",
    "name = 'RandomForest (n_estimators=1000)'\n",
    "\n",
    "train_all_sets(est_cls, rf_params, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest (n_estimators=1000) CV Scores:\n",
      "\tDesc\n",
      "\t\t- mean_absolute_error: 0.718 ± 0.022\n",
      "\t\t- rmse: 1.077 ± 0.021\n",
      "\t\t- r2_score: 0.804 ± 0.010\n",
      "\tFMorgan3\n",
      "\t\t- mean_absolute_error: 0.708 ± 0.021\n",
      "\t\t- rmse: 1.094 ± 0.029\n",
      "\t\t- r2_score: 0.797 ± 0.008\n",
      "\tDesc_FMorgan3\n",
      "\t\t- mean_absolute_error: 0.683 ± 0.017\n",
      "\t\t- rmse: 1.032 ± 0.013\n",
      "\t\t- r2_score: 0.820 ± 0.005\n",
      "\tDesc_scaled\n",
      "\t\t- mean_absolute_error: 0.717 ± 0.022\n",
      "\t\t- rmse: 1.076 ± 0.022\n",
      "\t\t- r2_score: 0.804 ± 0.011\n",
      "\tFMorgan3_scaled\n",
      "\t\t- mean_absolute_error: 0.708 ± 0.021\n",
      "\t\t- rmse: 1.094 ± 0.029\n",
      "\t\t- r2_score: 0.797 ± 0.008\n",
      "\tDesc_FMorgan3_scaled\n",
      "\t\t- mean_absolute_error: 0.682 ± 0.017\n",
      "\t\t- rmse: 1.032 ± 0.013\n",
      "\t\t- r2_score: 0.820 ± 0.005\n"
     ]
    }
   ],
   "source": [
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### SupportVectorMachine (gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = SVR\n",
    "svr_params = dict(cache_size=4096, verbose=verbose)\n",
    "name = 'SupportVectorMachine (gamma=\"scale\")'\n",
    "\n",
    "train_all_sets(est_cls, svr_params, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SupportVectorMachine (gamma=\"scale\") CV Scores:\n",
      "\tDesc\n",
      "\t\t- mean_absolute_error: 2.100 ± 0.037\n",
      "\t\t- rmse: 2.436 ± 0.035\n",
      "\t\t- r2_score: -0.004 ± 0.004\n",
      "\tFMorgan3\n",
      "\t\t- mean_absolute_error: 0.851 ± 0.025\n",
      "\t\t- rmse: 1.240 ± 0.035\n",
      "\t\t- r2_score: 0.740 ± 0.012\n",
      "\tDesc_FMorgan3\n",
      "\t\t- mean_absolute_error: 2.100 ± 0.037\n",
      "\t\t- rmse: 2.436 ± 0.035\n",
      "\t\t- r2_score: -0.004 ± 0.004\n",
      "\tDesc_scaled\n",
      "\t\t- mean_absolute_error: 0.876 ± 0.033\n",
      "\t\t- rmse: 1.282 ± 0.047\n",
      "\t\t- r2_score: 0.722 ± 0.015\n",
      "\tFMorgan3_scaled\n",
      "\t\t- mean_absolute_error: 1.090 ± 0.034\n",
      "\t\t- rmse: 1.466 ± 0.041\n",
      "\t\t- r2_score: 0.637 ± 0.014\n",
      "\tDesc_FMorgan3_scaled\n",
      "\t\t- mean_absolute_error: 1.020 ± 0.037\n",
      "\t\t- rmse: 1.400 ± 0.047\n",
      "\t\t- r2_score: 0.668 ± 0.016\n"
     ]
    }
   ],
   "source": [
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### SupportVectorMachine (gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = SVR\n",
    "svr_params = dict(cache_size=4096, verbose=verbose, gamma='auto')\n",
    "name = 'SupportVectorMachine (gamma=\"auto\")'\n",
    "\n",
    "train_all_sets(est_cls, svr_params, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SupportVectorMachine (gamma=\"auto\") CV Scores:\n",
      "\tDesc\n",
      "\t\t- mean_absolute_error: 2.016 ± 0.042\n",
      "\t\t- rmse: 2.362 ± 0.039\n",
      "\t\t- r2_score: 0.056 ± 0.009\n",
      "\tFMorgan3\n",
      "\t\t- mean_absolute_error: 1.612 ± 0.031\n",
      "\t\t- rmse: 1.926 ± 0.033\n",
      "\t\t- r2_score: 0.373 ± 0.007\n",
      "\tDesc_FMorgan3\n",
      "\t\t- mean_absolute_error: 1.642 ± 0.061\n",
      "\t\t- rmse: 2.052 ± 0.060\n",
      "\t\t- r2_score: 0.288 ± 0.027\n",
      "\tDesc_scaled\n",
      "\t\t- mean_absolute_error: 0.882 ± 0.035\n",
      "\t\t- rmse: 1.288 ± 0.048\n",
      "\t\t- r2_score: 0.719 ± 0.016\n",
      "\tFMorgan3_scaled\n",
      "\t\t- mean_absolute_error: 1.090 ± 0.034\n",
      "\t\t- rmse: 1.465 ± 0.041\n",
      "\t\t- r2_score: 0.637 ± 0.014\n",
      "\tDesc_FMorgan3_scaled\n",
      "\t\t- mean_absolute_error: 1.019 ± 0.037\n",
      "\t\t- rmse: 1.400 ± 0.047\n",
      "\t\t- r2_score: 0.669 ± 0.016\n"
     ]
    }
   ],
   "source": [
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Multi Layer Perceptron (early_stopping=False, hidden_layer_sizes=(500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = MLPRegressor\n",
    "mlp_params = dict(hidden_layer_sizes=(500, 500), verbose=verbose, random_state=seed)\n",
    "name = 'Multi Layer Perceptron (early_stopping=False, hidden_layer_sizes=(500, 500))'\n",
    "\n",
    "train_all_sets(est_cls, mlp_params, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Layer Perceptron (early_stopping=False, hidden_layer_sizes=(500, 500)) CV Scores:\n",
      "\tDesc\n",
      "\t\t- mean_absolute_error: 1012633.635 ± 1901209.033\n",
      "\t\t- rmse: 21348705.163 ± 39788481.265\n",
      "\t\t- r2_score: -343815646750142.125 ± 686407858301744.875\n",
      "\tFMorgan3\n",
      "\t\t- mean_absolute_error: 0.866 ± 0.025\n",
      "\t\t- rmse: 1.270 ± 0.047\n",
      "\t\t- r2_score: 0.727 ± 0.019\n",
      "\tDesc_FMorgan3\n",
      "\t\t- mean_absolute_error: 338523.902 ± 425838.671\n",
      "\t\t- rmse: 7667645.861 ± 9828414.798\n",
      "\t\t- r2_score: -26414204010101.684 ± 48045329912146.383\n",
      "\tDesc_scaled\n",
      "\t\t- mean_absolute_error: 0.726 ± 0.018\n",
      "\t\t- rmse: 1.102 ± 0.050\n",
      "\t\t- r2_score: 0.794 ± 0.022\n",
      "\tFMorgan3_scaled\n",
      "\t\t- mean_absolute_error: 1.037 ± 0.045\n",
      "\t\t- rmse: 1.457 ± 0.057\n",
      "\t\t- r2_score: 0.640 ± 0.024\n",
      "\tDesc_FMorgan3_scaled\n",
      "\t\t- mean_absolute_error: 0.968 ± 0.032\n",
      "\t\t- rmse: 1.383 ± 0.040\n",
      "\t\t- r2_score: 0.677 ± 0.014\n"
     ]
    }
   ],
   "source": [
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = MLPRegressor\n",
    "mlp_params = dict(hidden_layer_sizes=(500, 500), verbose=verbose, random_state=seed, early_stopping=True)\n",
    "name = 'Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(500, 500))'\n",
    "\n",
    "train_all_sets(est_cls, mlp_params, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(500, 500)) CV Scores:\n",
      "\tDesc\n",
      "\t\t- mean_absolute_error: 1608.938 ± 553.820\n",
      "\t\t- rmse: 35009.764 ± 10750.094\n",
      "\t\t- r2_score: -227620357.862 ± 122941121.087\n",
      "\tFMorgan3\n",
      "\t\t- mean_absolute_error: 0.894 ± 0.024\n",
      "\t\t- rmse: 1.297 ± 0.040\n",
      "\t\t- r2_score: 0.715 ± 0.016\n",
      "\tDesc_FMorgan3\n",
      "\t\t- mean_absolute_error: 121502.590 ± 217072.292\n",
      "\t\t- rmse: 2884203.108 ± 5226274.774\n",
      "\t\t- r2_score: -5867135604712.889 ± 11651594167381.072\n",
      "\tDesc_scaled\n",
      "\t\t- mean_absolute_error: 0.768 ± 0.034\n",
      "\t\t- rmse: 1.161 ± 0.090\n",
      "\t\t- r2_score: 0.770 ± 0.038\n",
      "\tFMorgan3_scaled\n",
      "\t\t- mean_absolute_error: 1.031 ± 0.037\n",
      "\t\t- rmse: 1.447 ± 0.057\n",
      "\t\t- r2_score: 0.645 ± 0.026\n",
      "\tDesc_FMorgan3_scaled\n",
      "\t\t- mean_absolute_error: 0.984 ± 0.029\n",
      "\t\t- rmse: 1.404 ± 0.035\n",
      "\t\t- r2_score: 0.666 ± 0.017\n"
     ]
    }
   ],
   "source": [
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(250, 250, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = MLPRegressor\n",
    "mlp_params = dict(hidden_layer_sizes=(250, 250, 250), verbose=verbose, random_state=seed, early_stopping=True)\n",
    "name = 'Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(250, 250, 250))'\n",
    "\n",
    "train_all_sets(est_cls, mlp_params, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Layer Perceptron (early_stopping=True, hidden_layer_sizes=(250, 250, 250)) CV Scores:\n",
      "\tDesc\n",
      "\t\t- mean_absolute_error: 342.263 ± 353.360\n",
      "\t\t- rmse: 7272.756 ± 7016.493\n",
      "\t\t- r2_score: -18027644.153 ± 27054677.449\n",
      "\tFMorgan3\n",
      "\t\t- mean_absolute_error: 0.869 ± 0.023\n",
      "\t\t- rmse: 1.265 ± 0.039\n",
      "\t\t- r2_score: 0.729 ± 0.016\n",
      "\tDesc_FMorgan3\n",
      "\t\t- mean_absolute_error: 710.157 ± 585.744\n",
      "\t\t- rmse: 16128.376 ± 13756.380\n",
      "\t\t- r2_score: -74358553.117 ± 84585812.796\n",
      "\tDesc_scaled\n",
      "\t\t- mean_absolute_error: 0.775 ± 0.008\n",
      "\t\t- rmse: 1.158 ± 0.033\n",
      "\t\t- r2_score: 0.773 ± 0.013\n",
      "\tFMorgan3_scaled\n",
      "\t\t- mean_absolute_error: 1.026 ± 0.038\n",
      "\t\t- rmse: 1.455 ± 0.053\n",
      "\t\t- r2_score: 0.642 ± 0.022\n",
      "\tDesc_FMorgan3_scaled\n",
      "\t\t- mean_absolute_error: 0.973 ± 0.035\n",
      "\t\t- rmse: 1.388 ± 0.053\n",
      "\t\t- r2_score: 0.674 ± 0.023\n"
     ]
    }
   ],
   "source": [
    "generate_score_board(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### XGradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cls = xgb.XGBRegressor\n",
    "xgb_params = dict(verbosity=2 if verbose else 0, random_state=seed, n_jobs=est_jobs)\n",
    "name = 'XGradientBoost'\n",
    "\n",
    "train_all_sets(est_cls, xgb_params, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGradientBoost CV Scores:\n",
      "\tDesc\n",
      "\t\t- mean_absolute_error: 1.020 ± 0.014\n",
      "\t\t- rmse: 1.353 ± 0.021\n",
      "\t\t- r2_score: 0.691 ± 0.007\n",
      "\tFMorgan3\n",
      "\t\t- mean_absolute_error: 1.094 ± 0.027\n",
      "\t\t- rmse: 1.423 ± 0.036\n",
      "\t\t- r2_score: 0.657 ± 0.011\n",
      "\tDesc_FMorgan3\n",
      "\t\t- mean_absolute_error: 1.018 ± 0.010\n",
      "\t\t- rmse: 1.346 ± 0.022\n",
      "\t\t- r2_score: 0.694 ± 0.005\n",
      "\tDesc_scaled\n",
      "\t\t- mean_absolute_error: 1.020 ± 0.014\n",
      "\t\t- rmse: 1.353 ± 0.021\n",
      "\t\t- r2_score: 0.691 ± 0.007\n",
      "\tFMorgan3_scaled\n",
      "\t\t- mean_absolute_error: 1.094 ± 0.027\n",
      "\t\t- rmse: 1.423 ± 0.036\n",
      "\t\t- r2_score: 0.657 ± 0.011\n",
      "\tDesc_FMorgan3_scaled\n",
      "\t\t- mean_absolute_error: 1.018 ± 0.010\n",
      "\t\t- rmse: 1.346 ± 0.022\n",
      "\t\t- r2_score: 0.694 ± 0.005\n"
     ]
    }
   ],
   "source": [
    "generate_score_board(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

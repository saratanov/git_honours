{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [11:52:38] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "/Users/u6676643/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#delfos copy for pka prediction\n",
    "import torch\n",
    "from torch import nn\n",
    "from mol2vec.features import mol2alt_sentence, mol2sentence, MolSentence, DfVec, sentences2vec\n",
    "from gensim.models import word2vec\n",
    "import pandas as pd\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import Chem\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: define solvent X and solute Y using mol2vec but don't add the substructures!!\n",
    "#step 2: run RNN in both directions on each molecule, then concatenate forward;reverse to get H and G\n",
    "#step 3: feed H and G into attention layer, generate attention alignment matrix, create contexts P and Q\n",
    "#step 4: maxpool H;P and G;Q into 2D feature vectors\n",
    "#step 5: create flattened input u;v and feed into linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified sentence2vec function to return lists of word vectors\n",
    "def sentences2vecs(sentences, model, unseen=None):\n",
    "    \"\"\"Generate vectors for each word in a sentence sentence (list) in a list of sentences.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sentences : list, array\n",
    "        List with sentences\n",
    "    model : word2vec.Word2Vec\n",
    "        Gensim word2vec model\n",
    "    unseen : None, str\n",
    "        Keyword for unseen words. If None, those words are skipped.\n",
    "        https://stats.stackexchange.com/questions/163005/how-to-set-the-dictionary-for-text-analysis-using-neural-networks/163032#163032\n",
    "    Returns\n",
    "    -------\n",
    "    list of arrays, each sentence -> array of word vectors\n",
    "    \"\"\"\n",
    "    keys = set(model.wv.key_to_index)\n",
    "    bigveclist = []\n",
    "    if unseen:\n",
    "        unseen_vec = model.wv.get_vector(unseen)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        veclist = []\n",
    "        if unseen:\n",
    "            veclist.append([model.wv.get_vector(y) if y in set(sentence) & keys\n",
    "                       else unseen_vec for y in sentence])\n",
    "        else:\n",
    "            veclist.append([model.wv.get_vector(y) for y in sentence \n",
    "                            if y in set(sentence) & keys])\n",
    "        vecarray = np.concatenate(veclist, axis=1)\n",
    "        vectensor = torch.Tensor(vecarray)\n",
    "        bigveclist.append(vectensor)\n",
    "    return bigveclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/model_300dim.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b09043af0dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#mol2vec model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmol2vec_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/model_300dim.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#create mol type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \"\"\"\n\u001b[1;32m   1921\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1922\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1923\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \"\"\"\n\u001b[0;32m-> 1457\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/model_300dim.pkl'"
     ]
    }
   ],
   "source": [
    "#step 1: mol2vec embedding\n",
    "\n",
    "data = pd.read_csv('data/ETMdata.csv')\n",
    "\n",
    "#mol2vec model\n",
    "mol2vec_model = word2vec.Word2Vec.load('models/model_300dim.pkl')\n",
    "\n",
    "#create mol type\n",
    "data['sol_mol'] = data.apply(lambda x: Chem.MolFromSmiles(x['solute']), axis=1)\n",
    "data['solv_mol'] = data.apply(lambda x: Chem.MolFromSmiles(x['solvent']), axis=1)\n",
    "\n",
    "#remove invalid smiles\n",
    "#data.replace(\"\", float(\"NaN\"), inplace=True)\n",
    "#data.dropna(subset = ['mol'], inplace=True)\n",
    "#print(data)\n",
    "\n",
    "#create sentences\n",
    "data['sol_sentence'] = data.apply(lambda x: mol2alt_sentence(x['sol_mol'],1), axis=1)\n",
    "data['solv_sentence'] = data.apply(lambda x: mol2alt_sentence(x['solv_mol'],1), axis=1)\n",
    "\n",
    "targets = torch.Tensor(data['pka'])\n",
    "sol_data = sentences2vecs(data['sol_sentence'], mol2vec_model, unseen='UNK')\n",
    "solv_data = sentences2vecs(data['solv_sentence'], mol2vec_model, unseen='UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.nn.utils.rnn import pack_sequence\n",
    "#X = pack_sequence(X,enforce_sorted = False)\n",
    "##TODO BATCHING VARIABLE SEQUENCE LENGTHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(G,H):\n",
    "    alpha = torch.exp(H@torch.t(G))\n",
    "    norm = torch.sum(alpha, dim=1)\n",
    "    norm = torch.pow(norm, -1)\n",
    "    alpha = alpha * norm[:, None]\n",
    "    return alpha\n",
    "\n",
    "def att(G,H):\n",
    "    Q = alpha(G,H)@G\n",
    "    inH = torch.cat((H,Q),1)\n",
    "    return inH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "epochs = 10\n",
    "n_features = 300\n",
    "n_hidden = 100\n",
    "\n",
    "class maxpool(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(maxpool, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d((L,2), stride=2)\n",
    "    def forward(self, X):\n",
    "        return self.maxpool(X)\n",
    "\n",
    "class dnet(nn.Module):\n",
    "    def __init__(self, n_features, D, FF):\n",
    "        super(dnet, self).__init__()\n",
    "    \n",
    "        self.biLSTM_X = nn.LSTM(n_features, D, bidirectional=True)\n",
    "        self.biLSTM_Y = nn.LSTM(n_features, D, bidirectional=True)\n",
    "        \n",
    "        self.FF = nn.Linear(4*D, FF)\n",
    "        self.out = nn.Linear(FF, 1)\n",
    "    \n",
    "    def forward(self,X,Y):\n",
    "        N = X.data.shape[0]\n",
    "        M = Y.data.shape[0]\n",
    "        \n",
    "        #turn input list of vec into correct shape\n",
    "        X = X.view(X.data.shape[0],1,X.data.shape[1]) #N rows\n",
    "        Y = Y.view(Y.data.shape[0],1,Y.data.shape[1]) #M rows\n",
    "        \n",
    "        #biLSTM to get hidden states\n",
    "        H, hcX = self.biLSTM_X(X, None) #Nx1x2D matrix\n",
    "        G, hcY = self.biLSTM_Y(Y, None) #Mx1x2D matrix\n",
    "        \n",
    "        #contexts\n",
    "        inG = att(H[:,0,:],G[:,0,:]) #Nx4D\n",
    "        inH = att(G[:,0,:],H[:,0,:]) #Mx4D\n",
    "        \n",
    "        #maxpool concatenated tensors\n",
    "        maxpool_X = maxpool(N)\n",
    "        maxpool_Y = maxpool(M)\n",
    "        u = maxpool_X(inH.view(1,inH.data.shape[0],inH.data.shape[1]))  #1x1x2D\n",
    "        v = maxpool_Y(inG.view(1,inG.data.shape[0],inG.data.shape[1]))  #1x1x2D\n",
    "        \n",
    "        #feed forward neural network\n",
    "        NN = torch.cat((u,v),2)\n",
    "        NN = self.FF(NN)\n",
    "        NN = nn.functional.relu(NN)\n",
    "        output = self.out(NN)\n",
    "        return output\n",
    "\n",
    "dmodel = dnet(300,150,2000)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(dmodel.parameters(), lr=0.0002, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition, 3D maxpool\n",
    "epochs = 10\n",
    "n_features = 300\n",
    "n_hidden = 100\n",
    "\n",
    "class maxpool(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(maxpool, self).__init__()\n",
    "        self.maxpool = nn.MaxPool3d((L,1,2), stride=1)\n",
    "    def forward(self, X):\n",
    "        return self.maxpool(X)\n",
    "    \n",
    "def att(G,H):\n",
    "    Q = alpha(G,H)@G\n",
    "    inH = torch.stack([H,Q],2)\n",
    "    return inH\n",
    "\n",
    "class dnet(nn.Module):\n",
    "    def __init__(self, n_features, D, FF):\n",
    "        super(dnet, self).__init__()\n",
    "    \n",
    "        self.biLSTM_X = nn.LSTM(n_features, D, bidirectional=True)\n",
    "        self.biLSTM_Y = nn.LSTM(n_features, D, bidirectional=True)\n",
    "        \n",
    "        self.FF = nn.Linear(4*D, FF)\n",
    "        self.out = nn.Linear(FF, 1)\n",
    "    \n",
    "    def forward(self,X,Y):\n",
    "        N = X.data.shape[0]\n",
    "        M = Y.data.shape[0]\n",
    "        \n",
    "        #turn input list of vec into correct shape\n",
    "        X = X.view(X.data.shape[0],1,X.data.shape[1]) #N rows\n",
    "        Y = Y.view(Y.data.shape[0],1,Y.data.shape[1]) #M rows\n",
    "        \n",
    "        #biLSTM to get hidden states\n",
    "        H, hcX = self.biLSTM_X(X, None) #Nx1x2D matrix\n",
    "        G, hcY = self.biLSTM_Y(Y, None) #Mx1x2D matrix\n",
    "        \n",
    "        #contexts\n",
    "        inG = att(H[:,0,:],G[:,0,:]) #Nx4D\n",
    "        inH = att(G[:,0,:],H[:,0,:]) #Mx4D\n",
    "        \n",
    "        #maxpool concatenated tensors\n",
    "        maxpool_X = maxpool(N)\n",
    "        maxpool_Y = maxpool(M)\n",
    "        u = maxpool_X(inH.view(1,inH.data.shape[0],inH.data.shape[1],inH.data.shape[2]))  #1x1x2D\n",
    "        v = maxpool_Y(inG.view(1,inG.data.shape[0],inG.data.shape[1],inG.data.shape[2]))  #1x1x2D\n",
    "        \n",
    "        #feed forward neural network\n",
    "        NN = torch.cat((u,v),2).view(1,1,600)\n",
    "        NN = self.FF(NN)\n",
    "        NN = nn.functional.relu(NN)\n",
    "        output = self.out(NN)\n",
    "        return output\n",
    "\n",
    "dmodel = dnet(300,150,2000)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(dmodel.parameters(), lr=0.0002, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "n_features = 300\n",
    "n_hidden = 100\n",
    "losslist = []\n",
    "for t in range(epochs):\n",
    "    for b in range(len(sol_data)):\n",
    "        solute = sol_data[b]\n",
    "        solvent = solv_data[0]\n",
    "        target = targets[b]  \n",
    "        output = dmodel(solute,solvent) \n",
    "        loss = criterion(output, target)  \n",
    "        losslist.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print('step : ' , t , 'loss : ' , loss.item())\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         526 function calls (518 primitive calls) in 0.078 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.078    0.078 {built-in method builtins.exec}\n",
      "        1    0.005    0.005    0.078    0.078 <string>:1(<module>)\n",
      "      9/1    0.000    0.000    0.073    0.073 module.py:715(_call_impl)\n",
      "        1    0.000    0.000    0.073    0.073 <ipython-input-208-c9036915f170>:23(forward)\n",
      "        2    0.000    0.000    0.070    0.035 rnn.py:555(forward)\n",
      "        2    0.069    0.035    0.069    0.035 {built-in method lstm}\n",
      "        2    0.000    0.000    0.002    0.001 <ipython-input-207-127204d06c41>:8(att)\n",
      "        2    0.001    0.000    0.001    0.001 <ipython-input-207-127204d06c41>:1(alpha)\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method exp}\n",
      "        2    0.000    0.000    0.000    0.000 <ipython-input-208-c9036915f170>:10(forward)\n",
      "        2    0.000    0.000    0.000    0.000 pooling.py:152(forward)\n",
      "        2    0.000    0.000    0.000    0.000 _jit_internal.py:257(fn)\n",
      "        2    0.000    0.000    0.000    0.000 functional.py:574(_max_pool2d)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method max_pool2d}\n",
      "        2    0.000    0.000    0.000    0.000 linear.py:92(forward)\n",
      "        2    0.000    0.000    0.000    0.000 functional.py:1669(linear)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'matmul' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 <ipython-input-208-c9036915f170>:7(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method cat}\n",
      "        4    0.000    0.000    0.000    0.000 module.py:223(__init__)\n",
      "       54    0.000    0.000    0.000    0.000 module.py:781(__setattr__)\n",
      "        2    0.000    0.000    0.000    0.000 pooling.py:17(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method zeros}\n",
      "        2    0.000    0.000    0.000    0.000 rnn.py:529(check_forward_args)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method pow}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method sum}\n",
      "        2    0.000    0.000    0.000    0.000 rnn.py:171(check_input)\n",
      "        1    0.000    0.000    0.000    0.000 functional.py:1124(relu)\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method t}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method relu}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "      112    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        2    0.000    0.000    0.000    0.000 {method 't' of 'torch._C._TensorBase' objects}\n",
      "      160    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "       10    0.000    0.000    0.000    0.000 module.py:765(__getattr__)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 overrides.py:1070(has_torch_function)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "       36    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "        2    0.000    0.000    0.000    0.000 _VF.py:25(__getattr__)\n",
      "        4    0.000    0.000    0.000    0.000 rnn.py:193(check_hidden_size)\n",
      "        6    0.000    0.000    0.000    0.000 overrides.py:1083(<genexpr>)\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        2    0.000    0.000    0.000    0.000 rnn.py:182(get_expected_hidden_size)\n",
      "        2    0.000    0.000    0.000    0.000 functional.py:1686(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        2    0.000    0.000    0.000    0.000 module.py:782(remove_from)\n",
      "        2    0.000    0.000    0.000    0.000 rnn.py:538(permute_hidden)\n",
      "        5    0.000    0.000    0.000    0.000 _jit_internal.py:750(is_scripting)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._C._is_torch_function_enabled}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"dmodel(X[2],Y[0])\", sort = \"cumtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch model definition\n",
    "epochs = 10\n",
    "n_features = 300\n",
    "n_hidden = 100\n",
    "batch_size = 32\n",
    "\n",
    "class maxpool(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(maxpool, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d((L,2), stride=2)\n",
    "    def forward(self, X):\n",
    "        return self.maxpool(X)\n",
    "\n",
    "class dnet(nn.Module):\n",
    "    def __init__(self, n_features, D, FF):\n",
    "        super(dnet, self).__init__()\n",
    "    \n",
    "        self.biLSTM_X = nn.LSTM(n_features, D, bidirectional=True)\n",
    "        self.biLSTM_Y = nn.LSTM(n_features, D, bidirectional=True)\n",
    "        \n",
    "        self.FF = nn.Linear(4*D, FF)\n",
    "        self.out = nn.Linear(FF, 1)\n",
    "    \n",
    "    def forward(self,X,Y):\n",
    "        N = X.data.shape[0]\n",
    "        M = Y.data.shape[0]\n",
    "        \n",
    "        #turn input list of vec into correct shape\n",
    "        X = X.view(X.data.shape[0],1,X.data.shape[1]) #N rows\n",
    "        Y = Y.view(Y.data.shape[0],1,Y.data.shape[1]) #M rows\n",
    "        \n",
    "        #biLSTM to get hidden states\n",
    "        H, hcX = self.biLSTM_X(X, None) #NxBx2D matrix\n",
    "        G, hcY = self.biLSTM_Y(Y, None) #MxBx2D matrix\n",
    "        \n",
    "        inG = torch.Tensor([att(G[:,b,:],H[:,b,:]) for b in range(batch_size)])\n",
    "        inH = torch.Tensor([att(H[:,b,:],G[:,b,:]) for b in range(batch_size)])\n",
    "        \n",
    "        #maxpool concatenated tensors\n",
    "        maxpool_X = maxpool(N)\n",
    "        maxpool_Y = maxpool(M)\n",
    "        u = maxpool_X(inH)  #1x1x2D\n",
    "        v = maxpool_Y(inG)  #1x1x2D\n",
    "        \n",
    "        #feed forward neural network\n",
    "        NN = torch.cat((u,v),2)\n",
    "        NN = self.FF(NN)\n",
    "        NN = nn.functional.relu(NN)\n",
    "        output = self.out(NN)\n",
    "        return output\n",
    "\n",
    "dmodel = dnet(300,150,2000)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(dmodel.parameters(), lr=0.0002, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function Module.type at 0x1127acee0>\n"
     ]
    }
   ],
   "source": [
    "print(dnet.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SolvDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-af2b7c4c6e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollate_fn_padd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def collate_fn_padd(batch):\n",
    "    '''\n",
    "    Padds batch of variable length\n",
    "\n",
    "    note: it converts things ToTensor manually here since the ToTensor transform\n",
    "    assume it takes in images rather than arbitrary tensors.\n",
    "    '''\n",
    "    ## get sequence lengths\n",
    "    lengths = torch.tensor([ t.shape[0] for t in batch ]).to(device)\n",
    "    ## padd\n",
    "    batch = [ torch.Tensor(t).to(device) for t in batch ]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch)\n",
    "    ## compute mask\n",
    "    mask = (batch != 0).to(device)\n",
    "    return batch, lengths, mask\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn = collate_fn_padd)\n",
    "\n",
    "for batch_idx, (x, t) in enumerate(loader):\n",
    "    print(x.shape, t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(epochs):\n",
    "    for b in range(len(X)):\n",
    "        solute = X[b]\n",
    "        solvent = Y[0]\n",
    "        target = targets[b]  \n",
    "\n",
    "        output = dmodel(solute,solvent) \n",
    "        print(output)\n",
    "        loss = criterion(output, target)  \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        optimizer.zero_grad() \n",
    "    print('step : ' , t , 'loss : ' , loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

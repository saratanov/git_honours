{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict as ddict, OrderedDict as odict\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "from rdkit.Chem import PandasTools, AllChem as Chem, Descriptors\n",
    "from rdkit.Chem.Descriptors import MolWt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn\n",
    "from rdkit.Chem.rdmolops import GetFormalCharge\n",
    "import torch\n",
    "import deepchem as dc\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imp\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/u6676643/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from modules.RNN import double_RNN\n",
    "from modules.MPNN import double_MPNN\n",
    "from modules.fit import *\n",
    "from modules.transfer import transfer_weights, finetune\n",
    "from modules.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/full_pka_data.csv')\n",
    "solute = data['Solute SMILES'].tolist()\n",
    "solvent = data['Solvent SMILES'].tolist()\n",
    "pka = data['pKa (avg)'].tolist()\n",
    "data_size = len(solute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(data_size))\n",
    "CV_ids, holdout_ids, _, _ = train_test_split(indices, solvent, test_size=0.2, random_state=1, stratify=solvent)\n",
    "datasets = data_maker(solute, solvent, pka)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training + testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMPNN = Model(name='DMPNN',\n",
    "              model=double_MPNN(MP_depth=3, MP_hidden=256, NN_depth=2, NN_hidden=512, activation='ReLU', \n",
    "                                atom_messages=False, dropout=0, interaction=None, readout='sum'),\n",
    "              lr=0.001,\n",
    "              batch_size=64,\n",
    "              model_type='torch',\n",
    "              data_type='graphs')\n",
    "DMPNN_att = Model(name='DMPNN with attention',\n",
    "              model=double_MPNN(MP_depth=4, MP_hidden=128, NN_depth=4, NN_hidden=64, activation='ELU', \n",
    "                                atom_messages=False, dropout=0, interaction='tanh', readout='mean'),\n",
    "              lr=0.001,\n",
    "              batch_size=64,\n",
    "              model_type='torch',\n",
    "              data_type='graphs')\n",
    "MPNN = Model(name='MPNN',\n",
    "             model=double_MPNN(MP_depth=3, MP_hidden=256, NN_depth=2, NN_hidden=512, activation='LeakyReLU', \n",
    "                                  atom_messages=True, dropout=0, interaction=None, readout='sum'),\n",
    "             lr=0.001,\n",
    "             batch_size=64,\n",
    "             model_type='torch',\n",
    "             data_type='graphs')\n",
    "MPNN_att = Model(name='MPNN with attention',\n",
    "             model=double_MPNN(MP_depth=2, MP_hidden=64, NN_depth=4, NN_hidden=512, activation='ReLU', \n",
    "                                  atom_messages=True, dropout=0, interaction='tanh', readout='max'),\n",
    "             lr=0.001,\n",
    "             batch_size=64,\n",
    "             model_type='torch',\n",
    "             data_type='graphs')\n",
    "RNN = Model(name='RNN',\n",
    "            model=double_RNN(NN_depth=3, NN_hidden=512, RNN_hidden=512, activation='ReLU', dropout=0.3,\n",
    "                             features=300, interaction=None, readout='max'),\n",
    "            lr=0.001,\n",
    "            batch_size=32,\n",
    "            model_type='torch',\n",
    "            data_type='sentences')\n",
    "RNN_att = Model(name='RNN with attention',\n",
    "                model=double_RNN(NN_depth=1, NN_hidden=1024, RNN_hidden=512, activation='PReLU', dropout=0.1,\n",
    "                                 features=300, interaction='exp', readout='max'),\n",
    "                lr=0.001,\n",
    "                batch_size=32,\n",
    "                model_type='torch',\n",
    "                data_type='sentences')\n",
    "#list of all models for testing\n",
    "models = [DMPNN, DMPNN_att, MPNN, MPNN_att, RNN, RNN_att]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = [f for f in listdir('trained/') if isfile(join('trained/', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_func(file):\n",
    "    if 'Water' in file:\n",
    "        task = 'Water pKa'\n",
    "    elif 'Gsolv' in file:\n",
    "        task = 'Gsolv'\n",
    "    else:\n",
    "        task = file[-11:-3]\n",
    "    return task\n",
    "\n",
    "model_weights = []\n",
    "for file in trained_models:\n",
    "    task = task_func(file)\n",
    "    if 'RNN_w' in file:\n",
    "        model_weights.append((RNN_att,file,task))\n",
    "    elif 'DMPNN_w' in file:\n",
    "        model_weights.append((DMPNN_att,file,task))        \n",
    "    elif 'MPNN_w' in file:\n",
    "        model_weights.append((MPNN_att,file,task))\n",
    "    elif 'RNN' in file:\n",
    "        model_weights.append((RNN,file,task))\n",
    "    elif 'DMPNN' in file:\n",
    "        model_weights.append((DMPNN,file,task))\n",
    "    elif 'MPNN' in file:\n",
    "        model_weights.append((MPNN,file,task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing DMPNN_Gsolv.pt ...\n",
      "testing MPNN_with_attention_Gsolv.pt ...\n",
      "testing MPNN_Gsolv.pt ...\n",
      "testing RNN_Gsolv.pt ...\n",
      "testing RNN_with_attention_Gsolv.pt ...\n",
      "testing DMPNN_with_attention_Gsolv.pt ...\n",
      "                  Model Pretraining task       MAE      RMSE\n",
      "0                 DMPNN            Gsolv  1.711399  2.430409\n",
      "1   MPNN with attention            Gsolv  1.618414  2.458323\n",
      "2                  MPNN            Gsolv  2.169771  2.914583\n",
      "3                   RNN            Gsolv  2.424599  3.430700\n",
      "4    RNN with attention            Gsolv  2.812207  3.793522\n",
      "5  DMPNN with attention            Gsolv  2.601547  3.374790\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"Holdout test\"\n",
    "results = ddict(list)\n",
    "for m, file, task in model_weights:\n",
    "    if task == 'Water pKa':\n",
    "        pass\n",
    "    else:\n",
    "        print('testing '+file+' ...')\n",
    "        data = datasets[m.data_type]\n",
    "\n",
    "        transfer_weights(m, file)\n",
    "\n",
    "        res = fit(m, data, holdout_ids, exp_name)\n",
    "\n",
    "        results['Model'].append(m.name)\n",
    "        results['Pretraining task'].append(task)\n",
    "        results['MAE'].append(res[0])\n",
    "        results['RMSE'].append(res[1])\n",
    "\n",
    "holdout_test = pd.DataFrame(results)\n",
    "print(holdout_test)\n",
    "holdout_test.to_csv('results/holdout_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing MPNN_with_attention_Water_pka.pt ...\n",
      "testing RNN_Water_pka.pt ...\n",
      "testing DMPNN_Water_pka.pt ...\n",
      "testing MPNN_Water_pka.pt ...\n",
      "testing RNN_with_attention_Water_pka.pt ...\n",
      "testing DMPNN_with_attention_Water_pka.pt ...\n",
      "                  Model Pretraining task       MAE      RMSE\n",
      "0   MPNN with attention        Water pKa  1.160310  1.686413\n",
      "1                   RNN        Water pKa  1.281696  1.872694\n",
      "2                 DMPNN        Water pKa  0.920751  1.435663\n",
      "3                  MPNN        Water pKa  0.927955  1.447016\n",
      "4    RNN with attention        Water pKa  1.194385  1.808636\n",
      "5  DMPNN with attention        Water pKa  0.999161  1.545486\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"Holdout test\"\n",
    "results = ddict(list)\n",
    "for m, file, task in model_weights:\n",
    "    if 'Water' in file:\n",
    "        print('testing '+file+' ...')\n",
    "        data = datasets[m.data_type]\n",
    "\n",
    "        transfer_weights(m, file)\n",
    "\n",
    "        res = fit(m, data, holdout_ids, exp_name)\n",
    "\n",
    "        results['Model'].append(m.name)\n",
    "        results['Pretraining task'].append(task)\n",
    "        results['MAE'].append(res[0])\n",
    "        results['RMSE'].append(res[1])\n",
    "\n",
    "holdout_test = pd.DataFrame(results)\n",
    "print(holdout_test)\n",
    "holdout_test.to_csv('results/holdout_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing MPNN_with_attention_Water_pka.pt ...\n",
      "[0.9440844, 1.4092151]\n",
      "finetuning...\n",
      "[0.8747762, 1.335492]\n",
      "testing RNN_Water_pka.pt ...\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"Holdout test\"\n",
    "results = ddict(list)\n",
    "for m, file, task in model_weights:\n",
    "    if 'Water' in file:\n",
    "        print('testing '+file+' ...')\n",
    "        data = datasets[m.data_type]\n",
    "\n",
    "        transfer_weights(m, file)\n",
    "\n",
    "        res = fit(m, data, holdout_ids, exp_name)\n",
    "\n",
    "        results['Model'].append(m.name)\n",
    "        results['Pretraining task'].append(task)\n",
    "        results['MAE'].append(res[0])\n",
    "        results['RMSE'].append(res[1])\n",
    "        results['Finetuning'].append(False)\n",
    "        print(res)\n",
    "        \n",
    "        print('finetuning...')\n",
    "        res = finetune(m, data, holdout_ids, exp_name, new_lr=0.0001)\n",
    "\n",
    "        results['Model'].append(m.name)\n",
    "        results['Pretraining task'].append(task)\n",
    "        results['MAE'].append(res[0])\n",
    "        results['RMSE'].append(res[1])\n",
    "        results['Finetuning'].append(True)\n",
    "        print(res)\n",
    "\n",
    "holdout_test = pd.DataFrame(results)\n",
    "print(holdout_test)\n",
    "holdout_test.to_csv('results/holdout_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

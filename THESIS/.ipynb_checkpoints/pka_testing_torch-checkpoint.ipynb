{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing for non-generic torch models:\n",
    "1. Delfos (with and without attention)\n",
    "2. MPNN (with and without attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [21:04:56] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict as ddict, OrderedDict as odict\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "from rdkit.Chem import PandasTools, AllChem as Chem, Descriptors\n",
    "from rdkit.Chem.Descriptors import MolWt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn\n",
    "from rdkit.Chem.rdmolops import GetFormalCharge\n",
    "import torch\n",
    "import deepchem as dc\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hyperopt import hp\n",
    "import imp\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)  # Display floats without scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/u6676643/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from modules.data import data_maker\n",
    "from modules.RNN import double_RNN\n",
    "from modules.fit import Model, fit\n",
    "from modules.myhyperopt import hyperopt_func\n",
    "from modules.MPNN import double_MPNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/full_pka_data.csv')\n",
    "solute = data['Solute SMILES'].tolist()\n",
    "solvent = data['Solvent SMILES'].tolist()\n",
    "pka = data['pKa (avg)'].tolist()\n",
    "data_size = len(solute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(data_size))\n",
    "CV_ids, holdout_ids, _, _ = train_test_split(indices, solvent, test_size=0.2, random_state=1, stratify=solvent)\n",
    "CV_datasets = data_maker(solute, solvent, pka, CV_ids)\n",
    "datasets = data_maker(solute, solvent, pka)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Hyperoptimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'double_RNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e875a298b6cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'RNN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdouble_RNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_type'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'torch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_type'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'sentences'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m param_space = {'features':300,\n\u001b[1;32m      4\u001b[0m                \u001b[0;34m'interaction'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                \u001b[0;34m'RNN_hidden'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RNN_hidden'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'double_RNN' is not defined"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "model_dict = {'name':'RNN', 'model':double_RNN, 'model_type':'torch', 'data_type':'sentences'}\n",
    "param_space = {'features':300,\n",
    "               'interaction':None,\n",
    "               'RNN_hidden':hp.choice('RNN_hidden', [128,256,512]),\n",
    "               'NN_hidden':hp.choice('NN_hidden', [64,128,256,512,1024,2048]),\n",
    "               'NN_depth':hp.choice('NN_depth', [1,2,3,4]),\n",
    "               'dropout':hp.choice('dropout', [0,0.1,0.2,0.3]),\n",
    "               'readout':hp.choice('readout', ['mean','sum','max']),\n",
    "               'activation':hp.choice('activation', ['ReLU','LeakyReLU','PReLU','tanh','SELU','ELU']),\n",
    "               'lr':hp.choice('lr', [1e-2,1e-3,1e-4]),\n",
    "               'batch_size':hp.choice('batch_size', [16,32,64])}\n",
    "model_param_names = ['features','interaction','RNN_hidden','NN_hidden','NN_depth','readout','activation']\n",
    "training_param_names = ['lr','batch_size']\n",
    "\n",
    "RNN_hyp_res = hyperopt_func(model_dict, model_param_names, training_param_names, param_space, CV_datasets)\n",
    "RNN_hyp_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN with attention\n",
    "model_dict = {'name':'RNN with attention', 'model':double_RNN, 'model_type':'torch', 'data_type':'sentences'}\n",
    "param_space = {'features':300,\n",
    "               'interaction':hp.choice('interaction', ['exp','tanh']),\n",
    "               'RNN_hidden':hp.choice('RNN_hidden', [128,256,512]),\n",
    "               'NN_hidden':hp.choice('NN_hidden', [64,128,256,512,1024,2048]),\n",
    "               'NN_depth':hp.choice('NN_depth', [1,2,3,4]),\n",
    "               'dropout':hp.choice('dropout', [0,0.1,0.2,0.3]),\n",
    "               'readout':hp.choice('readout', ['mean','sum','max']),\n",
    "               'activation':hp.choice('activation', ['ReLU','LeakyReLU','PReLU','tanh','SELU','ELU']),\n",
    "               'lr':hp.choice('lr', [1e-2,1e-3,1e-4]),\n",
    "               'batch_size':hp.choice('batch_size', [16,32,64])}\n",
    "model_param_names = ['features','interaction','RNN_hidden','NN_hidden','NN_depth','readout','activation']\n",
    "training_param_names = ['lr','batch_size']\n",
    "\n",
    "RNNatt_hyp_res = hyperopt_func(model_dict, model_param_names, training_param_names, param_space, CV_datasets)\n",
    "RNNatt_hyp_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 3/30 [1:01:20<9:12:04, 1226.82s/trial, best loss: 1.4481956958770752]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-682-a053626f488e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtraining_param_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mDMPNN_hyp_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperopt_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_param_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_param_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCV_datasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mDMPNN_hyp_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codes/testing/basicest.py\u001b[0m in \u001b[0;36mhyperopt_func\u001b[0;34m(model_dict, model_param_names, training_param_names, param_space, datasets, max_evals)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0mtimer_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m     best = fmin(fn=tester.objective, \n\u001b[0m\u001b[1;32m    477\u001b[0m                 \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             )\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codes/testing/basicest.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCV_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0mrun_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codes/testing/basicest.py\u001b[0m in \u001b[0;36mCV_fit\u001b[0;34m(model, data, datasets, folds, random_state)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpka_scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mfold_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0mfold_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codes/testing/basicest.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, ids, data, scaler, datasets)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;31m#evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'grad_variables' is deprecated. Use 'grad_tensors' instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrad_tensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             raise RuntimeError(\"'grad_tensors' and 'grad_variables' (deprecated) \"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#DMPNN\n",
    "model_dict = {'name':'DMPNN', 'model':double_MPNN, 'model_type':'torch', 'data_type':'SMILES'}\n",
    "param_space = {'atom_messages':False,\n",
    "               'MP_hidden':hp.choice('MP_hidden', [64,128,256,512]),\n",
    "               'MP_depth':hp.choice('MP_depth', [2,3,4]),\n",
    "               'readout':hp.choice('readout', ['mean','sum','max']),\n",
    "               'dropout':hp.choice('dropout', [0,0.1,0.2,0.3]),\n",
    "               'interaction':False,\n",
    "               'NN_depth':hp.choice('NN_depth', [1,2,3,4]),\n",
    "               'NN_hidden':hp.choice('NN_hidden', [64,128,256,512]),\n",
    "               'activation':hp.choice('activation', ['ReLU','LeakyReLU','PReLU','tanh','SELU','ELU']),\n",
    "               'lr':hp.choice('lr', [1e-2,1e-3,1e-4]),\n",
    "               'batch_size':hp.choice('batch_size', [16,32,64])}\n",
    "model_param_names = ['atom_messages','MP_hidden','MP_depth','readout','dropout','interaction','NN_depth','NN_hidden','activation']\n",
    "training_param_names = ['lr','batch_size']\n",
    "\n",
    "DMPNN_hyp_res = hyperopt_func(model_dict, model_param_names, training_param_names, param_space, CV_datasets)\n",
    "DMPNN_hyp_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DMPNN with attention\n",
    "model_dict = {'name':'DMPNN with attention', 'model':double_MPNN, 'model_type':'torch', 'data_type':'SMILES'}\n",
    "param_space = {'atom_messages':False,\n",
    "               'MP_hidden':hp.choice('MP_hidden', [64,128,256,512]),\n",
    "               'MP_depth':hp.choice('MP_depth', [2,3,4]),\n",
    "               'readout':hp.choice('readout', ['mean','sum','max']),\n",
    "               'dropout':hp.choice('dropout', [0,0.1,0.2,0.3]),\n",
    "               'interaction':hp.choice('interaction', ['exp','tanh']),\n",
    "               'NN_depth':hp.choice('NN_depth', [1,2,3,4]),\n",
    "               'NN_hidden':hp.choice('NN_hidden', [64,128,256,512]),\n",
    "               'activation':hp.choice('activation', ['ReLU','LeakyReLU','PReLU','tanh','SELU','ELU']),\n",
    "               'lr':hp.choice('lr', [1e-2,1e-3,1e-4]),\n",
    "               'batch_size':hp.choice('batch_size', [16,32,64])}\n",
    "model_param_names = ['atom_messages','MP_hidden','MP_depth','readout','dropout','interaction','NN_depth','NN_hidden','activation']\n",
    "training_param_names = ['lr','batch_size']\n",
    "\n",
    "DMPNNatt_hyp_res = hyperopt_func(model_dict, model_param_names, training_param_names, param_space, CV_datasets)\n",
    "DMPNNatt_hyp_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:35<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-678-48a40ebe0c3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtraining_param_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mMPNN_hyp_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperopt_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_param_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_param_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCV_datasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mMPNN_hyp_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codes/testing/basicest.py\u001b[0m in \u001b[0;36mhyperopt_func\u001b[0;34m(model_dict, model_param_names, training_param_names, param_space, datasets, max_evals)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0mtimer_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m     best = fmin(fn=tester.objective, \n\u001b[0m\u001b[1;32m    477\u001b[0m                 \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             )\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codes/testing/basicest.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCV_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0mrun_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codes/testing/basicest.py\u001b[0m in \u001b[0;36mCV_fit\u001b[0;34m(model, data, datasets, folds, random_state)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpka_scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mfold_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0mfold_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codes/testing/basicest.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, ids, data, scaler, datasets)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;31m#evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'grad_variables' is deprecated. Use 'grad_tensors' instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrad_tensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             raise RuntimeError(\"'grad_tensors' and 'grad_variables' (deprecated) \"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#MPNN\n",
    "model_dict = {'name':'MPNN', 'model':double_MPNN, 'model_type':'torch', 'data_type':'SMILES'}\n",
    "param_space = {'atom_messages':False,\n",
    "               'MP_hidden':hp.choice('MP_hidden', [64,128,256,512]),\n",
    "               'MP_depth':hp.choice('MP_depth', [2,3,4]),\n",
    "               'readout':hp.choice('readout', ['mean','sum','max']),\n",
    "               'dropout':hp.choice('dropout', [0,0.1,0.2,0.3]),\n",
    "               'interaction':False,\n",
    "               'NN_depth':hp.choice('NN_depth', [1,2,3,4]),\n",
    "               'NN_hidden':hp.choice('NN_hidden', [64,128,256,512]),\n",
    "               'activation':hp.choice('activation', ['ReLU','LeakyReLU','PReLU','tanh','SELU','ELU']),\n",
    "               'lr':hp.choice('lr', [1e-2,1e-3,1e-4]),\n",
    "               'batch_size':hp.choice('batch_size', [16,32,64])}\n",
    "model_param_names = ['atom_messages','MP_hidden','MP_depth','readout','dropout','interaction','NN_depth','NN_hidden','activation']\n",
    "training_param_names = ['lr','batch_size']\n",
    "\n",
    "MPNN_hyp_res = hyperopt_func(model_dict, model_param_names, training_param_names, param_space, CV_datasets)\n",
    "MPNN_hyp_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MPNN with attention\n",
    "model_dict = {'name':'MPNN with attention', 'model':double_MPNN, 'model_type':'torch', 'data_type':'SMILES'}\n",
    "param_space = {'atom_messages':False,\n",
    "               'MP_hidden':hp.choice('MP_hidden', [64,128,256,512]),\n",
    "               'MP_depth':hp.choice('MP_depth', [2,3,4]),\n",
    "               'readout':hp.choice('readout', ['mean','sum','max']),\n",
    "               'dropout':hp.choice('dropout', [0,0.1,0.2,0.3]),\n",
    "               'interaction':hp.choice('interaction', ['exp','tanh']),\n",
    "               'NN_depth':hp.choice('NN_depth', [1,2,3,4]),\n",
    "               'NN_hidden':hp.choice('NN_hidden', [64,128,256,512]),\n",
    "               'activation':hp.choice('activation', ['ReLU','LeakyReLU','PReLU','tanh','SELU','ELU']),\n",
    "               'lr':hp.choice('lr', [1e-2,1e-3,1e-4]),\n",
    "               'batch_size':hp.choice('batch_size', [16,32,64])}\n",
    "model_param_names = ['atom_messages','MP_hidden','MP_depth','readout','dropout','interaction','NN_depth','NN_hidden','activation']\n",
    "training_param_names = ['lr','batch_size']\n",
    "\n",
    "MPNNatt_hyp_res = hyperopt_func(model_dict, model_param_names, training_param_names, param_space, CV_datasets)\n",
    "MPNNatt_hyp_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [44:37<00:00, 89.25s/trial, best loss: 1.3505516265758195] \n",
      "Total training time (min): 44.623752204316666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.3505516265758195,\n",
       " 'params': {'bootstrap': True,\n",
       "  'max_depth': 512,\n",
       "  'max_features': 'auto',\n",
       "  'min_samples_leaf': 2,\n",
       "  'min_samples_split': 2,\n",
       "  'n_estimators': 2048,\n",
       "  'n_jobs': -1},\n",
       " 'run_time': 226.25426462799987,\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RF with descriptors\n",
    "model_dict = {'name':'RF with descriptors', 'model':RandomForestRegressor, 'model_type':'sklearn', 'data_type':'descriptors'}\n",
    "param_space = {'n_estimators':hp.choice('n_estimators', [32,64,128,256,512,1024,2048]),\n",
    "               'max_depth':hp.choice('max_depth', [16,32,64,128,256,512,None]),\n",
    "               'min_samples_split':hp.choice('min_samples_split', [2,4,8,16]),\n",
    "               'min_samples_leaf':hp.choice('min_samples_leaf', [1,2,4,8]),\n",
    "               'max_features':hp.choice('max_features', ['auto','sqrt']),\n",
    "               'bootstrap':hp.choice('bootstrap', [True,False]),\n",
    "               'n_jobs':-1}\n",
    "\n",
    "model_param_names = ['n_estimators','max_depth','min_samples_split','min_samples_leaf','max_features','bootstrap','n_jobs']\n",
    "training_param_names = []\n",
    "\n",
    "RFdesc_hyp_res = hyperopt_func(model_dict, model_param_names, training_param_names, param_space, CV_datasets)\n",
    "RFdesc_hyp_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [3:51:02<00:00, 462.08s/trial, best loss: 1.5674555405853379]   \n",
      "Total training time (min): 231.0397540024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.5674555405853379,\n",
       " 'params': {'bootstrap': True,\n",
       "  'max_depth': 512,\n",
       "  'max_features': 'auto',\n",
       "  'min_samples_leaf': 2,\n",
       "  'min_samples_split': 2,\n",
       "  'n_estimators': 2048,\n",
       "  'n_jobs': -1},\n",
       " 'run_time': 1238.881594587,\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RF with ECFP\n",
    "model_dict = {'name':'RF with ECFP', 'model':RandomForestRegressor, 'model_type':'sklearn', 'data_type':'ECFP'}\n",
    "param_space = {'n_estimators':hp.choice('n_estimators', [32,64,128,256,512,1024,2048]),\n",
    "               'max_depth':hp.choice('max_depth', [16,32,64,128,256,512,None]),\n",
    "               'min_samples_split':hp.choice('min_samples_split', [2,4,8,16]),\n",
    "               'min_samples_leaf':hp.choice('min_samples_leaf', [1,2,4,8]),\n",
    "               'max_features':hp.choice('max_features', ['auto','sqrt']),\n",
    "               'bootstrap':hp.choice('bootstrap', [True,False]),\n",
    "               'n_jobs':-1}\n",
    "\n",
    "model_param_names = ['n_estimators','max_depth','min_samples_split','min_samples_leaf','max_features','bootstrap','n_jobs']\n",
    "training_param_names = []\n",
    "\n",
    "RFecfp_hyp_res = hyperopt_func(model_dict, model_param_names, training_param_names, param_space, CV_datasets)\n",
    "RFecfp_hyp_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [21:12<00:00, 42.40s/trial, best loss: 1.2326064571528836]\n",
      "Total training time (min): 21.203471856133334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.2326064571528836,\n",
       " 'params': {'activation': 'logistic',\n",
       "  'batch_size': 32,\n",
       "  'early_stopping': True,\n",
       "  'hidden_layer_sizes': (512, 256, 128),\n",
       "  'solver': 'adam'},\n",
       " 'run_time': 146.33090689399978,\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MLP with descriptors\n",
    "model_dict = {'name':'MLP with descriptors', 'model':MLPRegressor, 'model_type':'sklearn', 'data_type':'descriptors'}\n",
    "param_space = {'hidden_layer_sizes':hp.choice('hidden_layer_sizes', [(128),(256,128),(512,256,128),(512,256),(256),(512),(64),(256,128,64),(128,64,32),(128,256,128),(256,256),(128,128)]),\n",
    "               'activation':hp.choice('activation', ['logistic','tanh','relu']),\n",
    "               'solver':'adam',\n",
    "               'batch_size':hp.choice('batch_size', [16,32,64,128,'auto']),\n",
    "               'early_stopping':True}\n",
    "\n",
    "model_param_names = ['hidden_layer_sizes','activation','solver','batch_size','early_stopping']\n",
    "training_param_names = []\n",
    "\n",
    "MLPdesc_hyp_res = hyperopt_func(model_dict, model_param_names, training_param_names, param_space, CV_datasets)\n",
    "MLPdesc_hyp_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [2:23:49<00:00, 287.65s/trial, best loss: 1.5294755988767599] \n",
      "Total training time (min): 143.82353783585003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.5294755988767599,\n",
       " 'params': {'activation': 'relu',\n",
       "  'batch_size': 16,\n",
       "  'early_stopping': True,\n",
       "  'hidden_layer_sizes': (256, 128, 64),\n",
       "  'solver': 'adam'},\n",
       " 'run_time': 461.70881920600004,\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MLP with ECFP\n",
    "model_dict = {'name':'MLP with ECFP', 'model':MLPRegressor, 'model_type':'sklearn', 'data_type':'ECFP'}\n",
    "param_space = {'hidden_layer_sizes':hp.choice('hidden_layer_sizes', [(128),(256,128),(512,256,128),(512,256),(256),(512),(64),(256,128,64),(128,64,32),(128,256,128),(256,256),(128,128)]),\n",
    "               'activation':hp.choice('activation', ['logistic','tanh','relu']),\n",
    "               'solver':'adam',\n",
    "               'batch_size':hp.choice('batch_size', [16,32,64,128,'auto']),\n",
    "               'early_stopping':True}\n",
    "\n",
    "model_param_names = ['hidden_layer_sizes','activation','solver','batch_size','early_stopping']\n",
    "training_param_names = []\n",
    "\n",
    "MLPecfp_hyp_res = hyperopt_func(model_dict, model_param_names, training_param_names, param_space, CV_datasets)\n",
    "MLPecfp_hyp_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [25:37<00:00, 51.26s/trial, best loss: 1.1962208378296566] \n",
      "Total training time (min): 25.630719183983334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.1962208378296566,\n",
       " 'params': {'colsample_bytree': 0.7,\n",
       "  'eta': 0.1,\n",
       "  'gamma': 0,\n",
       "  'max_depth': 8,\n",
       "  'min_child_weight': 2,\n",
       "  'n_estimators': 2048,\n",
       "  'n_jobs': -1,\n",
       "  'subsample': 0.9},\n",
       " 'run_time': 141.17223592899973,\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGB with descriptors\n",
    "model_dict = {'name':'XGB with descriptors', 'model':XGBRegressor, 'model_type':'sklearn', 'data_type':'descriptors'}\n",
    "param_space = {'n_estimators':hp.choice('n_estimators', [32,64,128,256,512,1024,2048,4096]),\n",
    "               'max_depth':hp.choice('max_depth', [1,2,4,8]),\n",
    "               'min_child_weight':hp.choice('min_child_weight', [1,2,4,8,16]),\n",
    "               'eta':hp.choice('eta', [0.1,0.2,0.3,0.4]),\n",
    "               'gamma':hp.choice('gamma', [0,0.1,0.2]),\n",
    "               'subsample':hp.choice('subsample', [0.6,0.7,0.8,0.9]),\n",
    "               'colsample_bytree':hp.choice('colsample_bytree', [0.6,0.7,0.8,0.9,1]),\n",
    "               'gamma':hp.choice('gamma', [0,0.1,0.2]),\n",
    "               'n_jobs':-1}\n",
    "\n",
    "model_param_names = ['n_estimators','max_depth','min_child_weight','eta','gamma','subsample','colsample_bytree','gamma','n_jobs']\n",
    "training_param_names = []\n",
    "\n",
    "XGBdesc_hyp_res = hyperopt_func(model_dict, model_param_names, training_param_names, param_space, CV_datasets)\n",
    "XGBdesc_hyp_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [3:01:13<00:00, 362.46s/trial, best loss: 1.4146270334817639]  \n",
      "Total training time (min): 181.2331836483667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.4146270334817639,\n",
       " 'params': {'colsample_bytree': 0.6,\n",
       "  'eta': 0.1,\n",
       "  'gamma': 0,\n",
       "  'max_depth': 8,\n",
       "  'min_child_weight': 2,\n",
       "  'n_estimators': 2048,\n",
       "  'n_jobs': -1,\n",
       "  'subsample': 0.8},\n",
       " 'run_time': 844.2109466850015,\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGB with ECFP\n",
    "model_dict = {'name':'XGB with ECFP', 'model':XGBRegressor, 'model_type':'sklearn', 'data_type':'ECFP'}\n",
    "param_space = {'n_estimators':hp.choice('n_estimators', [32,64,128,256,512,1024,2048,4096]),\n",
    "               'max_depth':hp.choice('max_depth', [1,2,4,8]),\n",
    "               'min_child_weight':hp.choice('min_child_weight', [1,2,4,8,16]),\n",
    "               'eta':hp.choice('eta', [0.1,0.2,0.3,0.4]),\n",
    "               'gamma':hp.choice('gamma', [0,0.1,0.2]),\n",
    "               'subsample':hp.choice('subsample', [0.6,0.7,0.8,0.9]),\n",
    "               'colsample_bytree':hp.choice('colsample_bytree', [0.6,0.7,0.8,0.9,1]),\n",
    "               'gamma':hp.choice('gamma', [0,0.1,0.2]),\n",
    "               'n_jobs':-1}\n",
    "\n",
    "model_param_names = ['n_estimators','max_depth','min_child_weight','eta','gamma','subsample','colsample_bytree','gamma','n_jobs']\n",
    "training_param_names = []\n",
    "\n",
    "XGBecfp_hyp_res = hyperopt_func(model_dict, model_param_names, training_param_names, param_space, CV_datasets)\n",
    "XGBecfp_hyp_res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training + testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMPNN = Model(name='D-MPNN',\n",
    "                model=double_MPNN(atom_messages=False),\n",
    "                model_type='torch',\n",
    "                data_type='graphs')\n",
    "DMPNN_att = Model(name='D-MPNN with attention',\n",
    "                    model=double_MPNN(atom_messages=False, interaction='exp'),\n",
    "                    model_type='torch',\n",
    "                    data_type='graphs')\n",
    "MPNN = Model(name='MPNN',\n",
    "                model=double_MPNN(atom_messages=True),\n",
    "                model_type='torch',\n",
    "                data_type='graphs')\n",
    "MPNN_att = Model(name='MPNN with attention',\n",
    "                    model=double_MPNN(atom_messages=True, interaction='exp'),\n",
    "                    model_type='torch',\n",
    "                    data_type='graphs')\n",
    "RNN = Model(name='RNN',\n",
    "              model=double_RNN(interaction=None),\n",
    "              model_type='torch',\n",
    "              data_type='sentences')\n",
    "RNN_att = Model(name='RNN with attention',\n",
    "                  model=double_RNN(interaction='exp'),\n",
    "                  model_type='torch',\n",
    "                  data_type='sentences')\n",
    "RF_desc = Model(name='Random forest with descriptors',\n",
    "                  model=RandomForestRegressor(bootstrap=True, max_depth=512, max_features='auto', min_samples_leaf=2, min_samples_split=2, n_estimators=2048, n_jobs=-1),\n",
    "                  model_type='sklearn',\n",
    "                  data_type='descriptors')\n",
    "RF_ECFP = Model(name='Random forest with ECFP',\n",
    "                  model=RandomForestRegressor(bootstrap=True, max_depth=512, max_features='auto', min_samples_leaf=2, min_samples_split=2, n_estimators=2048, n_jobs=-1),\n",
    "                  model_type='sklearn',\n",
    "                  data_type='ECFP')\n",
    "MLP_desc = Model(name='MLP with descriptors',\n",
    "                  model=MLPRegressor(activation='logistic', batch_size=32, early_stopping=True, hidden_layer_sizes=(512, 256, 128), solver='adam'),\n",
    "                  model_type='sklearn',\n",
    "                  data_type='descriptors')\n",
    "MLP_ECFP = Model(name='MLP with ECFP',\n",
    "                  model=MLPRegressor(activation='relu', batch_size=16, early_stopping=True, hidden_layer_sizes=(256, 128, 64), solver='adam'),\n",
    "                  model_type='sklearn',\n",
    "                  data_type='ECFP')\n",
    "RGB_desc = Model(name='RGBoost with descriptors',\n",
    "                  model=XGBRegressor(colsample_bytree=0.7, eta=0.1, gamma=0, max_depth=8, min_child_weight=2, n_estimators=2048, n_jobs=-1, subsample=0.9),\n",
    "                  model_type='sklearn',\n",
    "                  data_type='descriptors')\n",
    "RGB_ECFP = Model(name='RGBoost with ECFP',\n",
    "                  model=XGBRegressor(colsample_bytree=0.6, eta=0.1, gamma=0, max_depth=8, min_child_weight=2, n_estimators=2048, n_jobs=-1, subsample=0.8),\n",
    "                  model_type='sklearn',\n",
    "                  data_type='ECFP')\n",
    "#list of all models for testing\n",
    "models = [DMPNN, DMPNN_att, MPNN, MPNN_att, RNN, RNN_att, RF_desc, RF_ECFP, MLP_desc, MLP_ECFP, RGB_desc, RGB_ECFP]\n",
    "#models = [RF_desc, RF_ECFP, MLP_desc, MLP_ECFP, RGB_desc, RGB_ECFP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing MPNN ...\n",
      "testing D-MPNN ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-901d109fb17d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholdout_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codes/THESIS/modules/fit.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, test_ids, exp_name, train_ids)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mdesc_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'results'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scaler'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'desc_scaler'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdesc_scaler\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codes/THESIS/modules/fit.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, ids, data, scaler)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;31m#evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TODO: holdout data test\n",
    "exp_name = \"Holdout test\"\n",
    "results = ddict(list)\n",
    "for m in models:\n",
    "    print('testing '+m.name+' ...')\n",
    "    data = datasets[m.data_type]\n",
    "    \n",
    "    res = fit(m, data, holdout_ids, exp_name)\n",
    "    \n",
    "    results['Model'].append(m.name)\n",
    "    results['MAE'].append(res[0])\n",
    "    results['RMSE'].append(res[1])\n",
    "\n",
    "holdout_test = pd.DataFrame(results)\n",
    "print(holdout_test)\n",
    "holdout_test.to_csv('results/holdout_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import qqlot_2samples\n",
    "import pylab\n",
    "\n",
    "data = datasets[MPNN.data_type]\n",
    "targets, outputs = predict(MPNN, MPNN.experiments[0], data, holdout_ids)\n",
    "\n",
    "sm.qqplot_2samples(targets, outputs, line='45')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing prop 0.1 ...\n",
      "testing prop 0.2 ...\n",
      "testing prop 0.5 ...\n",
      "testing prop 0.75 ...\n",
      "                             Model  Train size   MAE  RMSE\n",
      "0   Random forest with descriptors         257 1.524 2.273\n",
      "1          Random forest with ECFP         257 1.551 2.282\n",
      "2             MLP with descriptors         257 1.938 2.641\n",
      "3                    MLP with ECFP         257 1.997 2.753\n",
      "4         RGBoost with descriptors         257 1.380 2.125\n",
      "5                RGBoost with ECFP         257 1.519 2.229\n",
      "6   Random forest with descriptors         515 1.276 2.061\n",
      "7          Random forest with ECFP         515 1.303 2.031\n",
      "8             MLP with descriptors         515 1.883 2.538\n",
      "9                    MLP with ECFP         515 2.128 2.877\n",
      "10        RGBoost with descriptors         515 1.078 1.809\n",
      "11               RGBoost with ECFP         515 1.231 1.991\n",
      "12  Random forest with descriptors        1288 0.818 1.523\n",
      "13         Random forest with ECFP        1288 0.958 1.687\n",
      "14            MLP with descriptors        1288 1.185 1.746\n",
      "15                   MLP with ECFP        1288 0.980 1.625\n",
      "16        RGBoost with descriptors        1288 0.611 1.310\n",
      "17               RGBoost with ECFP        1288 0.760 1.484\n",
      "18  Random forest with descriptors        1932 0.610 1.116\n",
      "19         Random forest with ECFP        1932 0.785 1.415\n",
      "20            MLP with descriptors        1932 0.886 1.266\n",
      "21                   MLP with ECFP        1932 0.684 1.256\n",
      "22        RGBoost with descriptors        1932 0.346 0.859\n",
      "23               RGBoost with ECFP        1932 0.521 1.115\n"
     ]
    }
   ],
   "source": [
    "#TODO: dataset size vs accuracy\n",
    "results = ddict(list)\n",
    "proportions = [0.1,0.2,0.5,0.75]\n",
    "\n",
    "for prop in proportions:\n",
    "    solvents = [solvent[i] for i in CV_ids]\n",
    "    train_ids,_,_,_ = train_test_split(CV_ids, solvents, test_size=1-prop, random_state=1, stratify=solvents)\n",
    "    train_size = len(train_ids)\n",
    "    exp_name = \"Training data size \"+str(prop)\n",
    "    print('testing prop '+str(prop)+' ...')\n",
    "    for m in models:\n",
    "        data = datasets[m.data_type]\n",
    "\n",
    "        res = fit(m, data, test_ids, exp_name, train_ids=train_ids)\n",
    "\n",
    "        results['Model'].append(m.name)\n",
    "        results['Train size'].append(train_size)\n",
    "        results['MAE'].append(res[0])\n",
    "        results['RMSE'].append(res[1])\n",
    "\n",
    "train_prop_test = pd.DataFrame(results)\n",
    "print(train_prop_test)\n",
    "train_prop_test.to_csv('results/train_prop_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing CS(=O)C ...\n",
      "testing C1CCOC1 ...\n",
      "testing CC#N ...\n",
      "testing CN(C)C=O ...\n",
      "testing C(CCl)Cl ...\n",
      "testing O ...\n",
      "                             Model LOSO solvent  Test size    MAE   RMSE\n",
      "0   Random forest with descriptors      CS(=O)C        130  7.217  7.937\n",
      "1          Random forest with ECFP      CS(=O)C        130  3.785  5.088\n",
      "2             MLP with descriptors      CS(=O)C        130 11.440 11.969\n",
      "3                    MLP with ECFP      CS(=O)C        130  5.030  6.729\n",
      "4         RGBoost with descriptors      CS(=O)C        130  3.370  3.996\n",
      "5                RGBoost with ECFP      CS(=O)C        130  2.625  3.125\n",
      "6   Random forest with descriptors      C1CCOC1         65  2.301  3.304\n",
      "7          Random forest with ECFP      C1CCOC1         65  3.741  4.340\n",
      "8             MLP with descriptors      C1CCOC1         65 13.904 14.879\n",
      "9                    MLP with ECFP      C1CCOC1         65  4.351  5.081\n",
      "10        RGBoost with descriptors      C1CCOC1         65  2.083  4.159\n",
      "11               RGBoost with ECFP      C1CCOC1         65  3.369  4.540\n",
      "12  Random forest with descriptors         CC#N        400  7.181  8.405\n",
      "13         Random forest with ECFP         CC#N        400  9.893 11.258\n",
      "14            MLP with descriptors         CC#N        400  4.316  5.495\n",
      "15                   MLP with ECFP         CC#N        400  9.989 11.330\n",
      "16        RGBoost with descriptors         CC#N        400  6.843  7.798\n",
      "17               RGBoost with ECFP         CC#N        400 10.315 11.567\n",
      "18  Random forest with descriptors     CN(C)C=O         20  4.852  5.474\n",
      "19         Random forest with ECFP     CN(C)C=O         20  3.291  3.786\n",
      "20            MLP with descriptors     CN(C)C=O         20 13.580 13.796\n",
      "21                   MLP with ECFP     CN(C)C=O         20  2.437  2.958\n",
      "22        RGBoost with descriptors     CN(C)C=O         20  6.393  6.566\n",
      "23               RGBoost with ECFP     CN(C)C=O         20  2.389  2.889\n",
      "24  Random forest with descriptors     C(CCl)Cl         88 33.420 34.178\n",
      "25         Random forest with ECFP     C(CCl)Cl         88 34.517 35.520\n",
      "26            MLP with descriptors     C(CCl)Cl         88 35.108 35.686\n",
      "27                   MLP with ECFP     C(CCl)Cl         88 36.169 36.890\n",
      "28        RGBoost with descriptors     C(CCl)Cl         88 33.653 34.529\n",
      "29               RGBoost with ECFP     C(CCl)Cl         88 36.280 37.046\n",
      "30  Random forest with descriptors            O       2519 15.621 15.947\n",
      "31         Random forest with ECFP            O       2519  7.244  8.073\n",
      "32            MLP with descriptors            O       2519  4.365  5.528\n",
      "33                   MLP with ECFP            O       2519 14.083 14.731\n",
      "34        RGBoost with descriptors            O       2519 31.353 31.689\n",
      "35               RGBoost with ECFP            O       2519  7.283  8.223\n"
     ]
    }
   ],
   "source": [
    "#LOSO\n",
    "results = ddict(list)\n",
    "solvent_set = list(set(solvent))\n",
    "\n",
    "for solv in solvent_set:\n",
    "    test_ids = [i for i, x in enumerate(solvent) if x == solv]\n",
    "    size = len(test_ids)\n",
    "    exp_name = \"LOSO \"+solv\n",
    "    print('testing '+solv+' ...')\n",
    "    for m in models:\n",
    "        try:\n",
    "            data = datasets[m.data_type]\n",
    "\n",
    "            res = fit(m, data, test_ids, exp_name)\n",
    "\n",
    "            results['Model'].append(m.name)\n",
    "            results['LOSO solvent'].append(solv)\n",
    "            results['Test size'].append(size)\n",
    "            results['MAE'].append(res[0])\n",
    "            results['RMSE'].append(res[1])\n",
    "        except:\n",
    "            print('error with model '+m.name)\n",
    "\n",
    "LOSO_test = pd.DataFrame(results)\n",
    "print(LOSO_test)\n",
    "LOSO_test.to_csv('results/LOSO_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing N ...\n",
      "testing O ...\n",
      "testing F ...\n",
      "testing P ...\n",
      "testing S ...\n",
      "testing Cl ...\n",
      "testing Br ...\n",
      "                             Model LOEO element  Test size    MAE   RMSE\n",
      "0   Random forest with descriptors            N       2311  2.858  4.082\n",
      "1          Random forest with ECFP            N       2311  3.623  4.820\n",
      "2             MLP with descriptors            N       2311  3.380  5.063\n",
      "3                    MLP with ECFP            N       2311  3.369  4.622\n",
      "4         RGBoost with descriptors            N       2311  2.974  4.326\n",
      "5                RGBoost with ECFP            N       2311  3.287  4.570\n",
      "6   Random forest with descriptors            O       2067  3.790  5.085\n",
      "7          Random forest with ECFP            O       2067  3.476  4.674\n",
      "8             MLP with descriptors            O       2067  3.620  4.840\n",
      "9                    MLP with ECFP            O       2067  3.058  4.221\n",
      "10        RGBoost with descriptors            O       2067  3.395  4.820\n",
      "11               RGBoost with ECFP            O       2067  3.579  4.845\n",
      "12  Random forest with descriptors            F        423  4.113  5.632\n",
      "13         Random forest with ECFP            F        423  3.734  5.569\n",
      "14            MLP with descriptors            F        423 15.936 20.241\n",
      "15                   MLP with ECFP            F        423  4.181  6.299\n",
      "16        RGBoost with descriptors            F        423  4.040  5.786\n",
      "17               RGBoost with ECFP            F        423  3.700  5.411\n",
      "18  Random forest with descriptors            P         68  5.537  8.122\n",
      "19         Random forest with ECFP            P         68  5.119  7.362\n",
      "20            MLP with descriptors            P         68  5.487  8.059\n",
      "21                   MLP with ECFP            P         68  4.878  7.429\n",
      "22        RGBoost with descriptors            P         68  5.107  8.069\n",
      "23               RGBoost with ECFP            P         68  5.061  7.293\n",
      "24  Random forest with descriptors            S        492  3.862  5.611\n",
      "25         Random forest with ECFP            S        492  4.206  6.334\n",
      "26            MLP with descriptors            S        492  3.493  4.923\n",
      "27                   MLP with ECFP            S        492  3.763  5.264\n",
      "28        RGBoost with descriptors            S        492  3.746  5.455\n",
      "29               RGBoost with ECFP            S        492  4.057  5.912\n",
      "30  Random forest with descriptors           Cl        413  1.524  2.679\n",
      "31         Random forest with ECFP           Cl        413  1.687  2.893\n",
      "32            MLP with descriptors           Cl        413  1.796  2.592\n",
      "33                   MLP with ECFP           Cl        413  1.927  3.082\n",
      "34        RGBoost with descriptors           Cl        413  1.399  2.452\n",
      "35               RGBoost with ECFP           Cl        413  1.808  3.118\n",
      "36  Random forest with descriptors           Br        112  1.184  1.680\n",
      "37         Random forest with ECFP           Br        112  1.945  3.250\n",
      "38            MLP with descriptors           Br        112  1.193  1.797\n",
      "39                   MLP with ECFP           Br        112  2.255  3.224\n",
      "40        RGBoost with descriptors           Br        112  1.089  1.479\n",
      "41               RGBoost with ECFP           Br        112  2.273  3.596\n"
     ]
    }
   ],
   "source": [
    "#LOEO\n",
    "results = ddict(list)\n",
    "element_set = ['N','O','F','P','S','Cl','Br']\n",
    "\n",
    "for ele in element_set:\n",
    "    test_ids = [i for i, x in enumerate(solute) if ele in x]\n",
    "    size = len(test_ids)\n",
    "    exp_name = \"LOEO \"+ele\n",
    "    print('testing '+ele+' ...')\n",
    "    for m in models:\n",
    "        data = datasets[m.data_type]\n",
    "\n",
    "        res = fit(m, data, test_ids, exp_name)\n",
    "\n",
    "        results['Model'].append(m.name)\n",
    "        results['LOEO element'].append(ele)\n",
    "        results['Test size'].append(size)\n",
    "        results['MAE'].append(res[0])\n",
    "        results['RMSE'].append(res[1])\n",
    "\n",
    "LOEO_test = pd.DataFrame(results)\n",
    "print(LOEO_test)\n",
    "LOEO_test.to_csv('results/LOEO_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing >150g/mol ...\n",
      "testing >200g/mol ...\n",
      "testing >250g/mol ...\n",
      "testing >300g/mol ...\n",
      "testing >350g/mol ...\n",
      "                             Model  LOMO mass cutoff  Test size   MAE  RMSE\n",
      "0   Random forest with descriptors               150       2191 2.844 4.749\n",
      "1          Random forest with ECFP               150       2191 2.819 4.505\n",
      "2             MLP with descriptors               150       2191 3.263 5.797\n",
      "3                    MLP with ECFP               150       2191 2.890 5.058\n",
      "4         RGBoost with descriptors               150       2191 2.719 4.578\n",
      "5                RGBoost with ECFP               150       2191 2.914 4.435\n",
      "6   Random forest with descriptors               200       1307 2.827 4.497\n",
      "7          Random forest with ECFP               200       1307 2.851 4.283\n",
      "8             MLP with descriptors               200       1307 3.138 5.265\n",
      "9                    MLP with ECFP               200       1307 2.890 4.533\n",
      "10        RGBoost with descriptors               200       1307 2.771 4.302\n",
      "11               RGBoost with ECFP               200       1307 3.059 4.523\n",
      "12  Random forest with descriptors               250        848 2.848 4.360\n",
      "13         Random forest with ECFP               250        848 3.454 5.503\n",
      "14            MLP with descriptors               250        848 3.157 5.827\n",
      "15                   MLP with ECFP               250        848 3.377 5.169\n",
      "16        RGBoost with descriptors               250        848 2.558 3.938\n",
      "17               RGBoost with ECFP               250        848 3.759 5.882\n",
      "18  Random forest with descriptors               300        564 2.831 4.360\n",
      "19         Random forest with ECFP               300        564 3.281 5.027\n",
      "20            MLP with descriptors               300        564 2.386 4.010\n",
      "21                   MLP with ECFP               300        564 3.194 4.818\n",
      "22        RGBoost with descriptors               300        564 2.603 3.990\n",
      "23               RGBoost with ECFP               300        564 3.372 4.833\n",
      "24  Random forest with descriptors               350        393 3.032 4.529\n",
      "25         Random forest with ECFP               350        393 3.227 4.642\n",
      "26            MLP with descriptors               350        393 2.437 3.362\n",
      "27                   MLP with ECFP               350        393 2.867 4.019\n",
      "28        RGBoost with descriptors               350        393 3.234 4.615\n",
      "29               RGBoost with ECFP               350        393 3.220 4.490\n"
     ]
    }
   ],
   "source": [
    "#LOMO\n",
    "results = ddict(list)\n",
    "solute_masses = [MolWt(Chem.MolFromSmiles(mol)) for mol in solute]\n",
    "mass_cutoffs = [150,200,250,300,350]\n",
    "\n",
    "for mass in mass_cutoffs:\n",
    "    test_ids = [i for i, x in enumerate(solute_masses) if x > mass]\n",
    "    size = len(test_ids)\n",
    "    exp_name = \"LOMO >\"+str(mass)+'g/mol'\n",
    "    print('testing >'+str(mass)+'g/mol ...')\n",
    "    for m in models:\n",
    "        try:\n",
    "            data = datasets[m.data_type]\n",
    "\n",
    "            res = fit(m, data, test_ids, exp_name)\n",
    "\n",
    "            results['Model'].append(m.name)\n",
    "            results['LOMO mass cutoff'].append(mass)\n",
    "            results['Test size'].append(size)\n",
    "            results['MAE'].append(res[0])\n",
    "            results['RMSE'].append(res[1])\n",
    "        except:\n",
    "            print('error with model '+m.name)\n",
    "\n",
    "LOMO_high_test = pd.DataFrame(results)\n",
    "print(LOMO_high_test)\n",
    "LOMO_high_test.to_csv('results/LOMO_high_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing <50g/mol ...\n",
      "testing <100g/mol ...\n",
      "testing <150g/mol ...\n",
      "testing <200g/mol ...\n",
      "testing <250g/mol ...\n",
      "testing <300g/mol ...\n",
      "testing <350g/mol ...\n",
      "                             Model  LOMO mass cutoff  Test size   MAE  RMSE\n",
      "0   Random forest with descriptors                50         28 5.262 7.096\n",
      "1          Random forest with ECFP                50         28 2.401 3.967\n",
      "2             MLP with descriptors                50         28 2.518 3.526\n",
      "3                    MLP with ECFP                50         28 4.154 5.884\n",
      "4         RGBoost with descriptors                50         28 4.479 6.072\n",
      "5                RGBoost with ECFP                50         28 2.285 3.779\n",
      "6   Random forest with descriptors               100        272 2.692 3.609\n",
      "7          Random forest with ECFP               100        272 2.183 3.589\n",
      "8             MLP with descriptors               100        272 2.422 3.820\n",
      "9                    MLP with ECFP               100        272 2.466 3.595\n",
      "10        RGBoost with descriptors               100        272 6.029 7.533\n",
      "11               RGBoost with ECFP               100        272 2.217 3.427\n",
      "12  Random forest with descriptors               150       1031 2.304 3.806\n",
      "13         Random forest with ECFP               150       1031 1.936 3.497\n",
      "14            MLP with descriptors               150       1031 1.955 3.646\n",
      "15                   MLP with ECFP               150       1031 2.053 3.523\n",
      "16        RGBoost with descriptors               150       1031 4.326 4.909\n",
      "17               RGBoost with ECFP               150       1031 1.976 3.369\n",
      "18  Random forest with descriptors               200       1915 2.376 3.700\n",
      "19         Random forest with ECFP               200       1915 2.230 3.611\n",
      "20            MLP with descriptors               200       1915 2.166 3.534\n",
      "21                   MLP with ECFP               200       1915 2.335 3.617\n",
      "22        RGBoost with descriptors               200       1915 2.202 3.597\n",
      "23               RGBoost with ECFP               200       1915 2.286 3.528\n",
      "24  Random forest with descriptors               250       2374 2.788 4.013\n",
      "25         Random forest with ECFP               250       2374 2.456 4.008\n",
      "26            MLP with descriptors               250       2374 2.509 3.726\n",
      "27                   MLP with ECFP               250       2374 2.813 4.085\n",
      "28        RGBoost with descriptors               250       2374 2.560 3.770\n",
      "29               RGBoost with ECFP               250       2374 2.532 3.838\n",
      "30  Random forest with descriptors               300       2658 3.071 4.879\n",
      "31         Random forest with ECFP               300       2658 3.168 4.618\n",
      "32            MLP with descriptors               300       2658 3.124 4.583\n",
      "33                   MLP with ECFP               300       2658 3.281 4.562\n",
      "34        RGBoost with descriptors               300       2658 3.378 5.134\n",
      "35               RGBoost with ECFP               300       2658 3.289 4.575\n",
      "36  Random forest with descriptors               350       2829 3.149 4.839\n",
      "37         Random forest with ECFP               350       2829 3.397 5.210\n",
      "38            MLP with descriptors               350       2829 3.693 5.794\n",
      "39                   MLP with ECFP               350       2829 3.556 5.048\n",
      "40        RGBoost with descriptors               350       2829 3.727 5.937\n",
      "41               RGBoost with ECFP               350       2829 3.505 4.889\n"
     ]
    }
   ],
   "source": [
    "#LOMO\n",
    "results = ddict(list)\n",
    "solute_masses = [MolWt(Chem.MolFromSmiles(mol)) for mol in solute]\n",
    "mass_cutoffs = [50,100,150,200,250,300,350]\n",
    "\n",
    "for mass in mass_cutoffs:\n",
    "    test_ids = [i for i, x in enumerate(solute_masses) if x < mass]\n",
    "    size = len(test_ids)\n",
    "    exp_name = \"LOMO <\"+str(mass)+'g/mol'\n",
    "    print('testing <'+str(mass)+'g/mol ...')\n",
    "    for m in models:\n",
    "        try:\n",
    "            data = datasets[m.data_type]\n",
    "\n",
    "            res = fit(m, data, test_ids, exp_name)\n",
    "\n",
    "            results['Model'].append(m.name)\n",
    "            results['LOMO mass cutoff'].append(mass)\n",
    "            results['Test size'].append(size)\n",
    "            results['MAE'].append(res[0])\n",
    "            results['RMSE'].append(res[1])\n",
    "        except:\n",
    "            print('error with model '+m.name)\n",
    "\n",
    "LOMO_low_test = pd.DataFrame(results)\n",
    "print(LOMO_low_test)\n",
    "LOMO_low_test.to_csv('results/LOMO_low_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing >0 ...\n",
      "testing >1 ...\n",
      "                             Model  LOCO charge  Test size   MAE   RMSE\n",
      "0   Random forest with descriptors            0       1487 6.218 10.726\n",
      "1          Random forest with ECFP            0       1487 5.811 10.139\n",
      "2             MLP with descriptors            0       1487 5.481 10.226\n",
      "3                    MLP with ECFP            0       1487 5.714 10.110\n",
      "4         RGBoost with descriptors            0       1487 6.038 10.630\n",
      "5                RGBoost with ECFP            0       1487 5.871 10.180\n",
      "6   Random forest with descriptors            1       1687 3.036  4.580\n",
      "7          Random forest with ECFP            1       1687 3.577  4.935\n",
      "8             MLP with descriptors            1       1687 3.730  5.675\n",
      "9                    MLP with ECFP            1       1687 2.976  4.163\n",
      "10        RGBoost with descriptors            1       1687 3.097  4.860\n",
      "11               RGBoost with ECFP            1       1687 3.169  4.507\n"
     ]
    }
   ],
   "source": [
    "#LOCO\n",
    "results = ddict(list)\n",
    "solute_charges = [GetFormalCharge(Chem.MolFromSmiles(mol)) for mol in solute]\n",
    "charge_list = [0,1]\n",
    "\n",
    "for charge in charge_list:\n",
    "    test_ids = [i for i, x in enumerate(solute_charges) if x == charge]\n",
    "    size = len(test_ids)\n",
    "    exp_name = \"LOCO \"+str(charge)\n",
    "    print('testing >'+str(charge)+' ...')\n",
    "    for m in models:\n",
    "        try:\n",
    "            data = datasets[m.data_type]\n",
    "\n",
    "            res = fit(m, data, test_ids, exp_name)\n",
    "\n",
    "            results['Model'].append(m.name)\n",
    "            results['LOCO charge'].append(charge)\n",
    "            results['Test size'].append(size)\n",
    "            results['MAE'].append(res[0])\n",
    "            results['RMSE'].append(res[1])\n",
    "        except:\n",
    "            print('error with model '+m.name)\n",
    "\n",
    "LOCO_test = pd.DataFrame(results)\n",
    "print(LOCO_test)\n",
    "LOCO_test.to_csv('results/LOCO_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250\n",
      "testing proton donor ...\n",
      "3024\n",
      "testing H-bond donor ...\n",
      "1734\n",
      "testing protonated amine ...\n",
      "500\n",
      "testing carboxylic acid ...\n",
      "189\n",
      "testing amide ...\n",
      "80\n",
      "testing ketone ...\n",
      "539\n",
      "testing ether ...\n",
      "427\n",
      "testing amine ...\n",
      "190\n",
      "testing nitrile ...\n",
      "312\n",
      "testing nitro ...\n",
      "1192\n",
      "testing hydroxyl alcohol ...\n",
      "484\n",
      "testing phenol ...\n",
      "72\n",
      "testing thiol ...\n",
      "13\n",
      "testing phosphoric acid ...\n",
      "                             Model       LOFO group  Test size   MAE  RMSE\n",
      "0   Random forest with descriptors     proton donor       2250 4.022 5.267\n",
      "1          Random forest with ECFP     proton donor       2250 3.816 4.962\n",
      "2             MLP with descriptors     proton donor       2250 5.207 6.636\n",
      "3                    MLP with ECFP     proton donor       2250 3.827 5.000\n",
      "4         RGBoost with descriptors     proton donor       2250 4.449 5.553\n",
      "..                             ...              ...        ...   ...   ...\n",
      "79         Random forest with ECFP  phosphoric acid         13 3.379 4.058\n",
      "80            MLP with descriptors  phosphoric acid         13 2.232 2.432\n",
      "81                   MLP with ECFP  phosphoric acid         13 3.007 3.789\n",
      "82        RGBoost with descriptors  phosphoric acid         13 2.413 2.866\n",
      "83               RGBoost with ECFP  phosphoric acid         13 2.674 3.624\n",
      "\n",
      "[84 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#LOFO\n",
    "results = ddict(list)\n",
    "pattern_list = [('proton donor','[!H0;F,Cl,Br,I,N+,$([OH]-*=[!#6]),+]'),\n",
    "             ('H-bond donor','[N,n,O;!H0]'),\n",
    "             ('protonated amine','[NH+,NH2+,NH3+,nH+,nH2+]'),\n",
    "             ('carboxylic acid','[CX3](=O)[OX2H1]'),\n",
    "             ('amide','[NX3][CX3](=[OX1])[#6]'),\n",
    "             ('ketone','[#6][CX3](=O)[#6]'),\n",
    "             ('ether','[OD2]([#6])[#6]'),\n",
    "             ('amine','[NX3;H2,H1;!$(NC=O)]'),\n",
    "             ('nitrile','[NX1]#[CX2]'),\n",
    "             ('nitro','[$([NX3](=O)=O),$([NX3+](=O)[O-])][!#8]'),\n",
    "             ('hydroxyl alcohol','[#6][OX2H]'),\n",
    "             ('phenol','[OX2H][cX3]:[c]'),\n",
    "             ('thiol','[#16X2H]'),\n",
    "             ('phosphoric acid','[$(P(=[OX1])([$([OX2H]),$([OX1-]),$([OX2]P)])([$([OX2H]),$([OX1-]),$([OX2]P)])[$([OX2H]),$([OX1-]),$([OX2]P)]),$([P+]([OX1-])([$([OX2H]),$([OX1-]),$([OX2]P)])([$([OX2H]),$([OX1-]),$([OX2]P)])[$([OX2H]),$([OX1-]),$([OX2]P)])]')]\n",
    "solute_mols = [Chem.MolFromSmiles(sol) for sol in solute]\n",
    "\n",
    "for name, smart in pattern_list:\n",
    "    patt = Chem.MolFromSmarts(smart)\n",
    "    test_ids = [i for i, x in enumerate(solute_mols) if x.HasSubstructMatch(patt)==True]\n",
    "    size = len(test_ids)\n",
    "    exp_name = \"LOFO \"+name\n",
    "    print('testing '+name+' ...')\n",
    "    for m in models:\n",
    "        try:\n",
    "            data = datasets[m.data_type]\n",
    "\n",
    "            res = fit(m, data, test_ids, exp_name)\n",
    "\n",
    "            results['Model'].append(m.name)\n",
    "            results['LOFO group'].append(name)\n",
    "            results['Test size'].append(size)\n",
    "            results['MAE'].append(res[0])\n",
    "            results['RMSE'].append(res[1])\n",
    "        except:\n",
    "            print('error with model '+m.name)\n",
    "\n",
    "LOFO_test = pd.DataFrame(results)\n",
    "print(LOFO_test)\n",
    "LOFO_test.to_csv('results/LOFO_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
